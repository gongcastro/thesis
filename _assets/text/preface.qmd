Some things are more easily talked about than done. Talking about *talking*---an activity sometimes referred to as *Linguistics*---is painfully difficult. Language is the most complex communicative system known, yet few people are surprised by the fact that infants pick it up so early in life, and so effortlessly. Some of those intrigued few people are developmentalists, whose scientific enterprise has kept a lucky bunch of them out of unemployment. For the last five years, I have been one of them. The present dissertation describes a tortuous learning adventure. Not by our infant participants---they are doing fine---but by me. 

I was not unfamiliar with the cognitive sciences when I started this journey, but my previous interests had been oriented towards cognition in non-human animals. Working with babies seemed to me as close as working with interstitial and substitutional solutes in refractory alloys^[This is a thing, a quick [Google search](https://www.sciencedirect.com/science/article/pii/S1359645420302743) revealed to me.]. It later turned out that rats and babies are quite similar from the point of view of the researcher: they cannot be instructed, they cannot talk, and they may defecate during an experimental session. My previous experience did not prepare me, however, for the traumatic experience that designing my first experiment was. This experience did not kill me, but contrary to common saying I doubt it made me stronger. Despite all the guidance and resources available to me, arranging counterbalanced stimuli lists while controlling for multiple linguistic variables in more than one language has been the closest I have been to solve a sudoku. And I say "closest" because I learnt that one does not ever get rid of the feeling of having made an experiment-killing mistake in the process. Starting data collection and welcoming families to the lab felt reassuring, as things seemed to be working. Until the pandemic. I have many things to be grateful for, in the last three years, as I have not experienced any major loss. My thesis cannot say the same. With the labs in Barcelona and Oxford intermittently closed for an indefinite period, we were faced with the challenge of continuing our longitudinal data collection. Without the invaluable generosity of the families, the present thesis would look very different (shorter, for the reader's bliss, but perhaps less substantial). In summary,



Language allows one to express a virtually infinite amount of concepts by combining a finite amount of elements. This makes language the most complex communicative system known. Part of what makes language so complex, yet so efficient, is that the linguistic signal encodes information at multiple levels. Jackendoff [-@jackendoff2002complexity] illustrates this through the simple English sentence *The little star's beside a big star*, breaking its structure at the phonological level (prosody, syllables, segments, morphophonology), syntactic, semantic and spatial structure. It soon becomes obvious that the level of detail one can go into is much finer that what the apparent simplicity of the example sentence suggests. The fact that the average English speaker---even a young one---could seamlessly grasp the information embedded in that sentence at all levels, contrasts with the complexity of the signal they are provided. 

Even more fascinating is the fact that humans acquire their native language quickly and effortlessly, without formal instruction. One might argue that this rapid language acquisition is supported by abundant and rich linguistic input. In this line, recent advances in connectionist models trained in next-word prediction tasks ---currently known as Large Language Models (LLMs) [e.g., @devlin2018bert; @brown2020language; @vaswani2017attention]---have shown that, with a virtually infinite amount of input and computational resources [@brown2020language], some of such models can generate strings of words that parallel human-produced text at all linguistic levels [@mahowald2023dissociating; @chang2023language; @piantadosi2023modern].

The performance of these models, though informative, contrast with the unparalleled efficiency with which a human infant acquires language. First, infants become familiar with central features of their native language before even receiving a cumulative amount of linguistic input several orders of magnitude smaller than that of LLMs [@frank2023bridging]. Learning language so efficiently cannot therefore rely on the size of the available language input. But neither can it build on virtually infinite computational resources, like LLMs: humans cognition and behaviour can only be understood as the outputs of a system that performs simpler operations under limited computational resources [@van2008tractable].

Human language acquisition, and all of its complexity, must be understood as the result of some interaction between a system that operates under computational limitations, over the rich information provided by available linguistic input. In their *Rethinking Innateness*, @elman1996rethinking illustrate this approach with using the following example, as described by @thomson1917growth:

> [...] honey cells start their lives as spherical objects. In the
hive these cells are packed together, each bee attempting to create as
much space as possible for itself within an individual cell. Viewed
along a plane, any single sphere can contact just six other spheres
[...]. When honey cells are packed together, the wax walls will undergo deformation. Furthermore, the surface tension between two honey cells acts to create a flat plane surface. Since each cell contacts just six other cells, the surface tension of the wax and the packing pressure of the bees will force each sphere into a hexagonal shape. The hexagonal shape maximizes the packing of
the hive space and the volume of each cell and offers the most economical use of the wax resource. Hence the labor of the bees and the forces of physics act in consortium to produce the hexagonal shape of the beehive. The bee doesn't need to "know" anything about hexagons. 

Complex patterns of results are widespread in language acquisition research. For instance, non-linearities are widespread in the observable outcomes of development. These observable learning outputs need not be the result of complex computations by the child. Advances in computation have shown how small, linear cumulative changes in a system can lead to complex, non-linear changes. Language acquisition reflects this. Neural networks show that some complex patterns observed in language acquisition can be explained in terms of simple computations on the speech input.

The present dissertation addresses the case of infants being raised hearing two languages. As most language acquisition researchers agree that studying bilingualism poses theoretical and methodological challenges that research in monolingual infants does not face. This increased complexity does not preclude the search for common mechanisms that both monolinguals and bilinguals exploit in their language acquisition journey, which sometimes result in divergent trajectories. Divergences between monolingual and bilingual language acquisition trajectories can be explained in terms of infants using common mechanisms to deal with a more complex input. The present dissertation addresses the case of bilinguals, as a lens to study language acquisition as a whole. In the same way bilingualism research build on findings in monolinguals, bilinguals can be studied as an opportunity to inform monolingual language acquisition research. Bilinguals represent a specific case of language acquisition in which infants require additional computations to than monolinguals.

In the present dissertation, we first discuss monolingual language acquisition, as a generally common ground with bilingual language acquisition. We then consider how a dual language exposure changes the conditions under which children acquire language. Finally, we delve into the domain of lexical acquisition and processing.

This thesis explores a small area of language acquisition research: how infants learn a specific type of linguistic unit called *words*, and whether bilingualism---the simultaneous acquisition of two language---impacts this process. Although some of the premises and claims expressed in the present work may apply to infants acquiring language though modalities other than the auditory, the scope of the present work is the developmental trajectories of hearing, typically developing infants. For this reason, most examples and arguments concern the auditory modality, and refer to events that are specifically relevant to hearing infants, like *sound*, *hearing*, *auditory*. We invite the reader to consider the case of deaf infants as a natural extension of the point made, whenever possible. For instance, note that we adopt a broad definition of *phonology* in which a phonological system is present, with the only difference to oral languages that the forms of the linguistic units is motor-visual.
