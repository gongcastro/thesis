---
title: "Chapter 3: Developmental trajectories of langugage non-selectivity in the bilingual lexicon"
---

```{r setup}
#| label: setup
#| echo: false
#| message: false
#| warning: false
# load objects
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(knitr)
library(kableExtra)
library(here)
library(ggrepel)
library(patchwork)
library(english)

options(readr.show_progress = FALSE,
		readr.show_col_types = FALSE,
		knitr.kable.NA = "-")

participants <- read_csv(here("data", "03-chapter-3", "data", "participants.csv"))
stimuli <- read_csv(here("data", "03-chapter-3","data", "stimuli.csv"))
vocabulary <- read_csv(here("data", "03-chapter-3", "data", "vocabulary.csv"))
attrition_trials <- read_csv(here("data", "03-chapter-3", "data", "attrition_trials.csv"))
attrition_participants <- read_csv(here("data", "03-chapter-3", "data", "attrition_participants.csv"))
bvq_data <- readRDS(here("data", "03-chapter-3", "data-raw", "bvq.rds"))
gaze <- read_csv(here("data", "03-chapter-3", "data", "gaze.csv"))
data_bcn <- read_csv(here("data", "03-chapter-3", "data", "data_bcn.csv"))
data_oxf <- read_csv(here("data", "03-chapter-3", "data", "data_oxf.csv"))
model_fits_bcn <- readRDS(here("data", "03-chapter-3", "results", "fit_list_bcn.rds"))
model_loos_bcn <- readRDS(here("data", "03-chapter-3", "results", "loos_bcn.rds"))
model_fits_oxf <- readRDS(here("data", "03-chapter-3", "results", "fit_list_oxf.rds"))
model_loos_oxf <- readRDS(here("data", "03-chapter-3", "results", "loos_oxf.rds"))

# prepare data
attrition <- lst(participants,
				 attrition_participants,
				 attrition_trials) |>
	purrr::reduce(inner_join, by = join_by(session_id)) |> 
	separate(is_valid_gaze_all,
			 paste0("is_valid_gaze_",
			 	   c("prime", "test", "test_any", "test_each")),
			 sep = ", ") |> 
	separate(is_valid_vocab_all,
			 paste0("is_valid_vocab_", 
			 	   c("prime", "target", "distractor")),
			 sep = ", ") |> 
	mutate(across(matches("is_valid_"), as.logical))

my_theme <- theme_minimal() +
	theme(panel.grid = element_blank(),
		  axis.line = element_line(colour = "black"),
		  text = element_text(size = 12, colour = "black"),
		  axis.text = element_text(colour = "black"))

theme_set(my_theme)

clrs <- c("#004AAD", "#C8102E", "#FF9E1F")

options(
	ggplot2.ordinal.fill = clrs,
	ggplot2.ordinal.colour = clrs,
	ggplot2.discrete.fill = clrs,
	ggplot2.discrete.colour = clrs,
	ggplot2.continuous.fill = ggplot2::scale_color_gradient,
	ggplot2.continuous.colour = ggplot2::scale_color_gradient
)

set.seed(1234)
```

## Introduction

Building a mental lexicon is a major achievement in the development of an infant: by storing representations of how familiar words sound and what they mean, an infant is able to make sense of their linguistic input. The foundations of an initial lexicon are in place before the end the first year of life [@tincoff1999some; @halle1994emergence; @vihman2004cross; @parise2012electrophysiological; @bergelson20126; @bergelson2015early]. This initial lexicon consists of only a few items; mainly words for people, interjections, body parts, and food [@tincoff2012six; @tardif2008baby], but it undergoes rapid growth during the second year of life [@ganger2004reexamining; @goldfield1990early; @bloom2002children; @mcmurray2007defusing; @bergelson2020comprehension]. According to parental reports, the average 15-month-old infant already understands more than 100 words, and by two years of age, they understand more than 400 [@frank2021variability]. This accelerated lexical developmental is reflected in infants' trajectories of word recognition: infants recognise familiar words faster and more efficiently as they approach their second birthday [@fernald1998rapid; @fernald2001half; @hurtado2007spoken]. Despite being exposed to a more complex linguistic input, bilinguals show equivalent trajectories of word acquisition and word recognition to their monolingual peers' [@vihman2007onset; @legacy2018vocabulary; @hoff2012dual; @de2014bilingual; @pearson1994patterns; @byers-heinlein2023sometimes; @bialystok2009bilingualism]. This is a remarkable deed for two reasons. First, bilingual infants receive a relatively reduced linguistic input in each of their languages, compared to monolinguals [@costa2014does; @cattani2014much; @thordardottir2011relationship]. Second, they face a more complex referential context: they often learn two labels for each referent (one in each language), which additionally may not be direct translations of each other [@au1990principle; @tsui2022translation; @bilson2015semantic; @de2006early]. The mechanisms that allow bilingual' trajectories of lexical developmental to keep up with monolinguals' are still unclear.

Previous studies have pointed to the similarity between the two languages of exposure as a facilitator of lexical acquisition in bilinguals [@floccia2018vocabulary; @blom2020cross; @gampe2021does]. @floccia2018vocabulary reported larger vocabulary sizes in bilingual toddlers leaning two languages that shared high lexical similarity. The authors collected parental reports of vocabulary data from a sample of 367 bilingual children living in the United Kingdom, who were learning English and an additional language (out of a diverse pool of 13 languages). The authors then calculated the average phono-lexical similarity between English and each of the additional languages. English and Dutch shared the highest similarity, while English and Mandarin shared the lowest. Overall, children's vocabulary sizes in the additional language was positively associated with the amount of language similarity between their two languages. For instance, English-Dutch bilinguals showed larger vocabulary sizes in Dutch than English-Mandarin bilinguals did in Mandarin. The authors suggested that the acquisition of words in the additional language might be facilitated by their cognate status (i.e., being phonologically similar to their translation equivalent). If this is the case, larger vocabulary sizes might then be expected in bilinguals learning two languages sharing a high proportion of cognates. This would be consistent with available evidence of an earlier acquisition of cognate words [@bosch2014first; @mitchell2022cognates; @garcia2023cognate; @schelletter2002effect].

The facilitation effect of cognateness is in line with the language non-selective account of bilingual lexical access. This account proposes that bilinguals activate both languages in parallel, even during monolingual situations. In adults, there is robust evidence in favour of this language non-selective account of lexical access [@marian1999activation; @groot1992determinants; @schwartz2007reading; @dijkstra1999recognition; @dufour1995matching; @dijkstra2010cross; @spivey1999cross]. @costa2000cognate presented highly-proficient Catalan-Spanish bilinguals with a series of pictures of familiar objects. Participants were asked to name each picture in Spanish. Unbeknownst to participants, the authors manipulated the cognate status pictures' labels in Catalan and Spanish. In half of the trials, the labels associated to the pictures were cognates (e.g., *cat*-*gat* [cat]), whereas in the other half of the trials the labels were non-cognates (e.g., *taula*-*mesa* [table]). Participants named pictures faster in cognate trials than in non-cognate trials. Spanish monolinguals showed equivalent naming times in both conditions. These results revealed that bilinguals activated their Catalan phonology, despite performing the naming task exclusively in Spanish: the visual recognition of the presented pictures led to the parallel activation of its associated phonological forms in both languages, which influenced the subsequent dynamics of word production.

Parallel activation has also been reported in the developing lexicon [@poarch2012cross; @bosma2020cognate; @singh2014one; @jardak2019labels; @von2019impact; @floccia2020translation; @bosma2019longitudinal]. @von2012language found evidence of cross-language phonological priming in a sample of 20 German-English bilinguals aged 21 to 43 months. In their experimental task, each trial begun with the auditory presentation of an English prime word, followed by a target word in German, and a pair of target and distractor pictures. The authors recorded participants' target picture looking as a measure of target word recognition. The authors manipulated the cross-linguistic phonological overlap between the prime and the target labels. In a *priming through translation* condition, the English prime labels (leg) did not overlap with the German target labels (*Stein* [stone]), but with their German translations (*Bein*) did. In the *unrelated* condition, prime and target labels were not phonologically related in either German or English. If participants accessed their lexicon in a language non-selective way, the auditory presentation of the prime label in English should lead to the co-activation of its German translation. If this is the case, target word recognition should be interfered by the prior activation of a phonologically related German prime label. Under this hypothesis, the authors anticipated an delayed target looking in priming through translation trials, compared to unrelated trials. The results supported this hypothesis. In spite of the relevance of @von2012language study, some methodological issues deserve some consideration. First, for most participants, exposure to English (the less prevalent language) was lower than the minimal amount conventionally considered the threshold for bilingual exposure [@byers-heinlein2021multilab; @rocha-hidalgo2023defining]. Second, some of the prime labels in the priming through translation condition were cognates. If both English and German labels overlap phonologically with the German target label, priming effects can be explained by interference between words from the same language, as opposed to cross-language interference. Third---and most critically---participants were exposed to both English and German word in a by-trial basis. This creates a context in which interference effects may not have arised from the competition between the prime translation and the target words, but between the target word and any other word in the other language. Paradigms in which the experimental task is conducted exclusively in one language, while cross-linguistic features are covertly manipulated, offer a methodologically stronger basis for studying language non-selectivity in the developing lexicon [@grosjean1997bilingual].

@mani2010infant designed an implicit naming task, in which primes consisted of pictures presented in silence, instead of auditory labels. In each trial, English monolingual infants were first presented with pictures of familiar objects for 1,500 ms. Then, a target-distractor picture pair was presented for 2,000 ms, and then the auditory label of the target picture was presented. Post-naming target looking was recorded for another 2,000 ms until the end of the trial, as a measure of target word recognition. The authors manipulated the phonological overlap between the prime and the target labels, so that in half of the trials both labels were phonologically related, sharing phonological onset (cat-cup), or phonologically unrelated (ball-comb). Prime, target and distractor were unrelated otherwise. At 18 months of age, participants showed a stronger looking preference for the target pictures after phonologically related prime pictures, compared to after phonologically unrelated primes. Since the prime pictures were presented in silence, their results suggested that infants implicitly named the prime pictures, and that the phonology of the resulting word interacted with the subsequent recognition of the auditory target word. Later, @mani2011phonological tested 21-month-old infants in the same task. This time, priming effects were observed in the opposite direction: when prime and target labels were phonologically related, participants showed significantly weaker target looking preference, compared to unrelated trials. The size of this interference effect was associated to participants' vocabulary size, and to the cohort size of the prime label. The authors interpreted this finding as indicating a developmental shift. At 18 months, participants' word recognition might have experienced a sub-lexical facilitation effect, in which the prior activation of the shared phonological onset between the prime and target labels boosted word recognition. In older participants, the lexicon might have reached a critical size at which the recognition of the target was delayed by the activation of its phonological cohort.

The implicit naming paradigm provides an ideal experimental paradigm to study the developing bilingual lexicon. By covertly manipulating the cross-linguistic relationship between the prime and target labels, parallel activation can be tested while participants are presented with auditory stimuli (target labels) exclusively in one of their languages [see @von2014bilinguals for a similar approach in bilingual adults]. Capitalizing on the language non-selective account of lexical access, we exploited the implicit naming to investigate the mechanisms behind the emergence of phonological priming effects in the bilingual developing lexicon. We tested a cohort of monolingual and bilingual infants learning Catalan and Spanish between 20 and 32 months of age. We compared the performance of participants with differing vocabulary sizes in the word recognition task. In order to circumvent the problem of limited vocabulary knowledge in the non-dominant language, we tested participants only in their dominant language [@costa2014does]. 

Following @mani2010infant, each trial in the task started with the silent presentation of a prime picture. Both monolingual and bilingual infants were expected to implicitly name the prime picture. According to the language non-selective hypothesis of lexical access, bilinguals should generate two labels for the prime picture, one in each language. To test this prediction, we manipulated the phonological similarity between the prime and the target words in both languages (see @fig-hypotheses). In *Related/Non-cognate* trials, prime and target labels shared phonological onset in only the language of test. For instance an infant tested in Catalan would be presented with a chair as prime picture ($\textbf{c}\text{adira}_{\text{CAT}}/\text{silla}_{\text{SPA}}$ [chair]) and with $\textbf{c}\text{ullera}_{\text{CAT}}$ [spoon] as target label. In line with @mani2011phonological, we anticipated that the phonological overlap between prime and target should modulate target word recognition in both monolinguals and bilinguals. This should be reflected in a delayed target looking preference, compared to *Unrelated* trials, in which prime and target did not share phonological onset. In *Related/Cognate* trials, the prime shared phonological onset with the target in both languages. For instance, the same infants tested in Catalan would be presented with a car as prime picture ($\textbf{c}\text{otxe}_{\text{CAT}}/\textbf{c}\text{oche}_{\text{SPA}}$) and with $\textbf{c}\text{ullera}_{\text{CAT}}$ [spoon] as target label. In bilinguals, parallel activation of the prime in both languages should increase the cohort of the target word, leading to stronger interference effects in this condition, compared to *Related/Non-cognate* and *Unrelated* trials.

![Predicted priming effects (or their absence) in the *Related/Cognate*, *Related/Non-cognate*, and *Unrelated* conditions, with examples for a participant tested in Catalan. Words represent lexical representations. Lexical representations of the task-relevant language (Catalan) are depicted inside grey boxes. Solid arrows indicate within-language priming effects, and dashed lines indicate cross-language priming effects. In *Related/Cognate* (A) and *Related/Non-cognate* (B) trials, the recognition of the Catalan target word \textipa{ku"Le.R@} [spoon] is predicted to be modulated by the prior activation of the prime label in Catalan. In *Related/Cognate* trials, the parallel activation of the prime label in Spanish is predicted to increase the strength of the priming effect.](../_assets/img/hypotheses.png){#fig-hypotheses fig-align="center"}

In line with previous studies in monolinguals, we further predicted that the strength of the lexical interference effects in the *Related/Non-cognate* and *Related/Cognate* conditions would be associated to participants' vocabulary size. Target word recognition should be delayed by the activation of a larger cohort of phonologically related words [@mani2011phonological; @chow2017spoken; @avila2021longitudinal; @mayor2014infant]. We defined vocabulary size as the amount of words participants were reported to understand in their dominant language by their caregivers. The choice of the dominant language for calculating vocabulary sizes is due to several reasons. First, it allows a more fair comparison between monolinguals (who do not know any language other than their dominant language) and bilinguals (who may know words in a second language). Second, since participants were tested exclusively in their dominant language, their vocabulary size in the dominant language is more likely to be associated to participants' performance in the task. Third, previous work on word recognition in bilinguals suggests that vocabulary size in the dominant language predicts participants' performance better than total vocabulary (in which vocabulary sizes in both languages are summed together) [@marchman2010vocabulary].

Because of the short-lived effects of cross-language activation on lexical processing, and to maximise the probability of detecting priming effects, we introduced a change in the sequence of the trials relative to the original implementation by @mani2010infant. We presented target auditory labels immediately after the offset of the prime picture, and before the onset of the target and distractor pictures. By presenting prime pictures and target auditory labels closer in time, implicit naming of the prime picture should be more likely to influence the recognition of the target word. To test the effects of this methodological change, we first run a control experiment, Study 1, in which we tested a group of same-aged English monolinguals. In Study 2, we tested a group of monolinguals and bilinguals learning Catalan and Spanish.

## Study 1

In this study, we conducted a conceptual replication of @mani2010infant and @mani2011phonological. We tested a group of English monolinguals aged 20 to 32 months, living in the Oxfordshire area (United Kingdom). As just said, participants were tested exclusively in English. As in the original studies, we manipulated the phonological relationship between the prime and the target label. We expected participants’ target looking to change as a function of the phonological relatedness between the prime and target English labels. This would reveal that participants implicitly named the prime pictures, generating a phonological label that influenced the subsequent recognition of a phonologically related word. In half of the trials the English prime label was phonologically related to its Spanish translation, that it they were cognates; in the other half they were not phonologically related (non-cognates)^[It was initially planned to collected data from English monolinguals and English-Spanish bilinguals in Oxford, therefore the manipulation of the cognate status of the words in English and Spanish. Due to time limitations imposed by the COVD-19 lockdown between 2020 and 2022, collecting data from bilinguals was not possible. We report the available data from English monolinguals as a control for Catalan and Spanish monolinguals and bilinguals from Barcelona in Study 2.]. Given participants’ lack of knowledge of Spanish (or any language other than English), participants’ performance was predicted to be unaffected by the cognate status of the primes.

In this study, we conducted a conceptual replication of @mani2010infant and @mani2011phonological. We tested a group of English monolinguals aged 20 to 32 months, living in the Oxfordshire area (United Kingdom). As highlighted in the introduction, participants were tested exclusively in English, their dominant language. As in the original studies, we manipulated the phonological relationship between the prime and the target label. In line with @mani2011phonological, we predicted participants' target looking to change as a function of the phonological relatedness between the prime and target English labels. This would reveal that participants implicitly named the prime pictures, generating a phonological label that influenced the subsequent recognition of a phonologically related word. To establish a monolingual baseline for all conditions in Study 2, we also manipulated the cognate status of the prime in English and Spanish: in half of the trials the English prime label was phonologically related to its Spanish translation. Given participants' lack of familiarity with Spanish (or any language other than English), participants' performance was predicted to be unaffected by the cognate status of the primes. 

### Methods

All materials, data, and reproducible code can be found at the OSF ([https://osf.io/hy984/](https://osf.io/ckydb/)) and GitHub (<https://github.com/gongcastro/cognate-priming>) repositories. This study was conducted according to guidelines laid down in the Declaration of Helsinki, and was approved by the Drug Research Ethical Committee (CEIm) of the IMIM Parc de Salut Mar, reference 2020/9080/I and the Medical Sciences Research Ethics Board at the University of Oxford, reference R60939/RE009. Before every testing session, caregivers were asked to read and sign an informed consent form, and were given a token of appreciation at the end of it.

#### Participants

```{r}
#| label: participants-numbers-oxf
participants_oxf <- dplyr::filter(participants, location == "Oxford")

n_participants_total <- nrow(distinct(participants_oxf, child_id))
n_sessions_total <- count(participants_oxf)

n_participants_sex <- participants_oxf |>
	distinct(sex, child_id) |>
	count(sex)

n_participants_sessions <- participants_oxf |>
	count(child_id, name = "n_sessions") |>
	count(n_sessions) |>
	group_split(n_sessions) |>
	purrr::set_names(paste0("session_", 1:2)) |>
	purrr::map("n")

ages <- participants_oxf |>
	summarise(n = n(),
			  n_participants = n_distinct(child_id),
			  across(age, lst(mean, sd, min, max)),
			  across(matches("doe_"), lst(mean, sd)),
			  age_vctr = list(age),
			  .by = c(lp, test_language))

suppressWarnings({
	time_diffs <- participants_oxf |>
		arrange(child_id, session_id, age) |>
		mutate(n_session = 1:n()) |>
		select(child_id, session_id, session_n, age) |>
		dplyr::filter(child_id %in% participants_oxf$child_id[duplicated(participants_oxf$child_id)]) |>
		pivot_wider(
			id_cols = child_id,
			names_from = session_n,
			values_from = age,
			names_repair = janitor::make_clean_names) |>
		rowwise() |>
		mutate(diff_min = x2 - x1) |>
		ungroup() |>
		summarise(diff_min = min(diff_min, na.rm = TRUE))
})
```

We collected data from `r n_participants_total` children (`r n_participants_sex$n[1]` female, `r n_participants_sex$n[2]` male, with `r english::words(n_participants_sex$n[3])` additional participants' sex not being reported; Age: *Mean* = `r round(ages$age_mean, 2)` months, *SD* = `r round(ages$age_sd, 2)`, *Range* = `r round(ages$age_min, 2)`--`r round(ages$age_max, 2)`) (see @tbl-participants for a detailed summary of participants' age and language profile), living in the Oxfordshire area (United Kingdom). Participants were tested at the Oxford BabyLab at the University of Oxford. Families were recruited from maternity rooms in private hospitals and social media, and contacted via phone when the child's age spanned between 20 and 32 months. From the `r n_participants_total` children that participated, `r n_participants_sessions$session_1` participated once, and `r n_participants_sessions$session_2` participated twice. Recurrent participants were tested with at least `r round(time_diffs, 2)$diff_min` months of difference. We gathered a total of `r n_sessions_total$n` testing sessions. All participants were being raised in exclusively British English monolingual homes. Participants' vision was normal, none used glasses or any other type of vision corrector.

\newpage

\blandscape

```{r tbl-participants}
#| label: tbl-participants
#| tbl-cap: "Demographic and linguistic profile of testing sessions in Study 1. The number of excluded testing sessions and participants is indicated between parentheses."
tbl_data <- participants |>
	separate(doe, c("doe_spanish", "doe_catalan", 
					"doe_english", "doe_other"), 
			 sep = ", ") |>
	mutate(across(matches("doe"), as.double)) |> 
	select(-matches("other")) |>
	arrange(lp, test_language) |>
	distinct(session_id, child_id, .keep_all = TRUE) |>
	mutate(study = if_else(location == "Oxford",
						   "Study 1",
						   "Study 2"),
		   test_language = paste0(test_language, " dominant"),
		   lp = gsub(" \\(English\\)", "", lp)) |>
	inner_join(attrition_participants,
			   by = join_by(session_id)) |>
	summarise(n = n(),
			  n_participants = length(unique(child_id)),
			  across(age, lst(mean, sd)),
			  across(matches("doe_"), lst(mean, sd)),
			  .by = c(lp, study, test_language, is_valid_participant)) |>
	pivot_wider(
		id_cols = c(lp, study, test_language),
		names_from = is_valid_participant,
		values_from = is.numeric) |>
	select(lp, study, test_language, starts_with("n_"), matches("TRUE"),
		   n_FALSE, n_participants_FALSE) |>
	arrange(study, lp, test_language) |> 
	rename_with(\(x) gsub("_TRUE", "", x)) |> 
	mutate(n = paste0(n, " (", n_FALSE, ")"),
		   n_participants = paste0(n_participants, " (", n_participants_FALSE, ")"),
		   age = sprintf("%.2f (%.2f)", age_mean, age_sd),
		   across(matches("doe_"), \(x) x*100),
		   doe_spa = sprintf("%.2f (%.2f)", doe_spanish_mean, doe_spanish_sd),
		   doe_cat = sprintf("%.2f (%.2f)", doe_catalan_mean, doe_catalan_sd),
		   doe_eng = sprintf("%.2f (%.2f)", doe_english_mean, doe_english_sd)) |> 
	select(test_language, n, n_participants, age, doe_eng, doe_cat, doe_spa) 

kable(tbl_data,
	  format = "latex",
	  digits = 1,
	  booktabs = TRUE,
	  escape = FALSE,
	  col.names = c(" ", "Test sessions", "Participants",
	  			  "\\textit{M} (\\textit{SD})", 
	  			  "\\textit{M} (\\textit{SD})", 
	  			  "\\textit{M} (\\textit{SD})",
	  			  "\\textit{M} (\\textit{SD})"),
	  align = "lrrrrr") |> 
	add_header_above(c(" " = 1,
					   "Sample size" = 2,
					   "Age (months)" = 1,
					   "English" = 1,
					   "Catalan" = 1,
					   "Spanish" = 1)) |> 
	add_header_above(c(" " = 4,
					   "Degree of Exposure (%)" = 3)) |> 
	pack_rows(index = c("Study 1: Monolingual" = 1,
						"Study 2: Monolingual" = 2,
						"Study 2: Bilingual" = 2)) |> 
	row_spec(c(1, 3), hline_after = TRUE)
```

\elandscape

```{r vocab-values-oxf}
vocabulary_oxf <- inner_join(vocabulary,
							 select(participants_oxf, session_id),
							 by = join_by(session_id))

vocabulary_oxf_exc <- nrow(participants_oxf) - nrow(vocabulary_oxf)
```

We collected vocabulary data using parental responses to the Oxford Communicative Development Inventory (OCDI) [@hamilton2000infant]. The OCDI is an adaptation of the MacArthur-Bates Communicative Development Inventory [@fenson1994variability] to British English. The OCDI includes a vocabulary checklist containing 418 words from 21 semantic-functional categories (e.g., action words, animals, household objects, adverbs, etc.). For each word, caregivers are asked to answer if they child is able to *understand*, *understand and say* or does not understand or say the word. We calculated participants' receptive vocabulary size scores as the number of words that caregivers marked as *understands* or *understands and says*. Families were sent the questionnaire immediately after each experimental session, and were given two weeks to fill it. In the case that a complete response to the OCDI was not provided within the two-week limit, the participants' testing session was excluded from the analyses (*n* = `r vocabulary_oxf_exc`). @fig-vocabulary-oxf shows the distribution of participants' vocabulary sizes across ages.

```{r fig-vocabulary}
#| label: fig-vocabulary-oxf
#| fig-cap: "Participant receptive vocabulary sizes across ages and language profiles. For descritive purposes, mean and standard error of the mean are indicated, as calculated using a linear regression model."
#| fig-width: 5
#| fig-height: 4
#| out-width: 70%
vocab_plot_data <- vocabulary |>
	inner_join(dplyr::filter(attrition_participants, is_valid_participant),
			   by = join_by(session_id)) |>
	inner_join(
		select(
			participants, location, lp, age,
			child_id, session_id, age_group
		),
		by = join_by(child_id, session_id)
	) |>
	dplyr::filter(is_valid_participant) |>
	select(
		child_id, session_id, vocab_id, is_imputed, l1_count,
		lp, location, age_group, age
	) |>
	mutate(
		location = factor(location,
						  levels = c("Oxford", "Barcelona")
		),
		lp = gsub(" \\(English\\)", "", lp),
		side = case_when(
			location == "Oxford" ~ "both",
			lp == "Monolingual" ~ "left",
			lp == "Bilingual" ~ "right"
		),
		study = if_else(location == "Oxford",
						"Study 1 (English)", "Study 2 (Catalan/Spanish)"
		)
	)

vocab_plot_means <- vocab_plot_data |>
	summarise(
		l1_count_sd = sd(l1_count, na.rm = TRUE),
		l1_count = mean(l1_count, na.rm = TRUE),
		n = n(),
		.by = c(age, side, lp, study)
	) |>
	mutate(
		.lower = l1_count - (l1_count_sd / sqrt(n)),
		.upper = l1_count + (l1_count_sd / sqrt(n))
	)

vocab_plot_data |>
	dplyr::filter(study == "Study 1 (English)") |>
	ggplot(aes(age, l1_count,
			   side = side
	)) +
	geom_point(
		size = 2,
		shape = 1,
		colour = "grey",
		alpha = 3 / 4,
		stroke = 1
	) +
	geom_smooth(
		method = "lm",
		formula = "y ~ x",
		colour = "black",
		fill = "black"
	) +
	labs(
		x = "Age (months)",
		y = "Vocabulary size",
		colour = "Group",
		fill = "Group"
	) +
	scale_y_continuous(
		limits = c(0, 575),
		breaks = seq(0, 1e3, 100)
	) +
	scale_x_continuous(breaks = seq(0, 50, 2)) +
	theme(
		panel.grid.major.y = element_line(
			linetype = "dotted",
			colour = "grey"
		),
		legend.position = "top",
		legend.title = element_blank()
	)
```

#### Design

Participants were presented with 32 trials in random order, which belonged to two conditions: *Related* and *Unrelated* trials. In *Related* trials (*n* = 16), the English label of the prime was phonologically related to the target label, sharing phonological onset (e.g., /**\textipa{"t}**\textipa{\*ri:}/$_{\text{ENG}} [\text{tree}]$--/**\textipa{"t}**\textipa{\*r2k}/$_{\text{ENG}} [\text{truck}]$). In *Unrelated* trials, the prime and target labels did not share phonological onset (e.g., /\textipa{"dO:}/$_{\text{ENG}} [\text{door}]$--/\textipa{"s6k}/$_{\text{ENG}} [\text{sock}]$). Especial attention was paid to avoiding semantic or taxonomic relationships between prime and target words, and between prime and distractor words. Distractors were always phonologically unrelated to the prime and target labels in the same trial.

@fig-task illustrates the sequence of a trial. Each trial started with the presentation of an attention getter for 3,000 ms. Then, the prime picture was presented in silence in the centre of the screen for 1,500 milliseconds. Fifty milliseconds after the offset of the prime image, an auditory label was played, 700 milliseconds after the onset of the word, the target and distractor pictures were presented side-by-side during 1,000 milliseconds until the end of the trial. After this, the attention getter of the next trial was immediately presented. Each experimental session lasted approximately 10 minutes.


\newpage

\blandscape

![Experimental task design with examples in Catalan. In each trial, the prime image is presented in silence for 1,500 ms. Then the auditory target label is presented, and finally the target and distractor pictures are presented side-by-side for 2,000 ms. In cognate trials (*n* = 8), Catalan *and* Spanish prime labels shared phonological onset with the target label. In non-cognate trials (*n* = 8), only the Catalan prime label shared phonological onset with the target label. In unrelated trials (*n* = 16), none of the prime labels shared phonological onset with the target label.](../_assets/img/design.png){#fig-task fig-align="center"}

\elandscape

#### Stimuli

```{r stim-stats}
durations <- stimuli |>
	summarise(
		across(
			duration,
			lst(mean, sd, min, max)
		),
		.by = c(test_language)
	) %>%
	mutate(across(is.numeric, \(x) format(round(x * 1e3, 2), big.mark = ","))) %>%
	split(janitor::make_clean_names(.$test_language))
```

We created four lists of trials, across which the same target-distractor pair appeared with a different prime, counterbalancing the condition to which it belonged. For instance, in list one the *ball*-*trousers* pair was preceded by *bike* (*Related/Cognate*), by *butterfly* (*Related/Non-cognate*) in list two, and by *star* and *nose* (*Unrelated*) in lists three and four (see Appendix A for a detailed description of the stimuli). @tbl-stimuli shows a detailed summary of the stimuli properties, broken down by trial type and testing language. Trials included in each condition had equivalent length (number of phonemes) and lexical frequency. Lexical frequencies were extracted from the English corpora from the CHILDES database [@macwhinney2000childes; @sanchez2019childes] as counts per million words, and transformed into Zipf scores for easier cross-language comparison [@zipf1945meaning; @van2014subtlex]. Audios had an average duration of `r durations$english$duration_mean` ms (*SD* = `r durations$english$duration_sd`, *Range* = `r durations$english$duration_min`--`r durations$english$duration_max`).

\newpage

\blandscape

```{r tbl-stimuli}
#| label: tbl-stimuli
#| tbl-cap: "Summary of stimuli properties in Studies 1 and 2 by trial type. Values are summarised using the mean and the standard deviation (between parentheses)."
tbl_data <- stimuli |>
	separate(freq, paste0("freq_", c("prime", "target", "distractor")),
			 sep = ", ") |>
	separate(nphon, paste0("nphon_", c("prime", "target", "distractor")),
			 sep = ", ") |>
	separate(familiarity, paste0("familiarity_", c("prime", "target", "distractor")),
			 sep = ", ") |> 
	mutate(across(matches("freq_|nphon_|familiarity_"), as.double)) |> 
	summarise(across(c(matches("nphon_|freq_|familiarity_")),
					 list(sd = \(x) sd(x, na.rm = TRUE),
					 	 mean = \(x) mean(x, na.rm = TRUE))),
			  .by = c(trial_type, test_language)) |>
	select(-c(matches("distractor"))) |>
	mutate(test_language = if_else(test_language == "English",
								   paste0("Study 1: ", test_language),
								   paste0("Study 2: ", test_language)),
		   trial_type = case_when(trial_type=="Cognate" ~ "Related/Cognate",
		   					   trial_type=="Non-cognate" ~ "Related/Non-cognate",
		   					   trial_type=="Unrelated" ~ "Unrelated",
		   					   .default = NA),
		   nphon_prime = sprintf("%.2f (%.2f)",
		   					  nphon_prime_mean, nphon_prime_sd),
		   nphon_target = sprintf("%.2f (%.2f)", 
		   					   nphon_target_mean, nphon_target_sd),
		   freq_prime = sprintf("%.2f (%.2f)", 
		   					 freq_prime_mean, freq_prime_sd),
		   freq_target = sprintf("%.2f (%.2f)",
		   					  freq_target_mean, freq_target_sd),
		   fam_prime = sprintf("%.2f (%.2f)", 
		   					familiarity_prime_mean, familiarity_prime_sd),
		   fam_target = sprintf("%.2f (%.2f)", 
		   					 familiarity_target_mean, familiarity_target_sd)) |> 
	arrange(test_language) |> 
	select(trial_type, matches("nphon|freq|fam"), -matches("mean|sd"))


kable(tbl_data,
	  format = "latex",
	  digits = 1,
	  booktabs = TRUE,
	  escape = FALSE,
	  col.names = c("Condition",
	  			  "\\textit{M} (\\textit{SD})", 
	  			  "\\textit{M} (\\textit{SD})", 
	  			  "\\textit{M} (\\textit{SD})",
	  			  "\\textit{M} (\\textit{SD})", 
	  			  "\\textit{M} (\\textit{SD})", 
	  			  "\\textit{M} (\\textit{SD})"),
	  align = "lrrrrrr")  |> 
	add_header_above(c(" " = 1,
					   "Word length (phonemes)" = 2,
					   "Lexical frequency (Zipf)" = 2,
					   "Familiarity (%)" = 2)) |> 
	pack_rows(index = c("Study 1: English" = 3,
						"Study 2: Catalan" = 3,
						"Study 2: Spanish" = 3)) |> 
	row_spec(c(3, 6), hline_after = TRUE)
```

\elandscape

The auditory stimuli were natural exemplars of the selected target words, spoken by a Southern British English female speaker who was instructed to pronounce each word in a toddler-directed manner. We used the Audacity and Praat [@boersma2001speak] software packages to trim, denoised, and normalised their amplitude. The visual stimuli were realistic photographic representations of a typical exemplars of the prime, target, and distractor words. Image backgrounds were removed from the original pictures using the GNU Image Manipulation Program (GIMP), resized to a rectangle of a maximum of 400 pixels height or wide, and finally placed in the centre of a 50% grey rectangle square of 500 $\times$ 500 pixels. The final stimuli had a resolution of 72 dpi. When presented in the eye-tracker screen, the areas of interest (AOI) occupied an area of 13.23 $\times$ 13.23 cm (11.613$^{\circ}$ visual angle from participants' perspective).


#### Procedure

Testing took place in a sound-proof room at the BabyLab of the University of Oxford. Participants sat on their caregivers' lap in a dimly lit testing booth while the experimenter conducted the experiment from outside. Caregivers were instructed to keep their eyes shut (to avoid recording their gaze, instead of the participant's), to be still, and to avoid interacting with the participant verbally or non-verbally. Participants sat at approximately 65 cm from the eye-tracker and a 23-inches screen with $1929\times1080$ resolution. The study was run on Windows 7 (64-bit), using a custom Matlab script, PresentMate, based on the PsychToolbox-3 extension (3.0.10, 32 bit) [@kleiner2007s; @brainard1997psychophysics; @pelli1997videotoolbox]. Visual fixations were recorded using a Tobii TX300 eye-tracker (Tobii Technology, Stockholm, Sweden) and a 23-in screen of 1920 $\times$ 1080 resolution. The Tobii Analytics SDK 3.0 was used to interact with the eye-tracking while the experiment was running. Sampling rate was set at 120 Hz. A 9-point calibration was performed before every experimental session, in which the picture of a colourful beach ball was presented. We set a 55% grey background for the screen during calibration and stimuli presentation. Auditory stimuli were presented through two loudspeakers located behind the screen, one to each side. The experimenter monitored the experimental from outside the room using a centrally located video camera place above the screen. After a successful calibration the experimenter triggered the onset of the first trial. Trials were presented uninterruptedly and without intervention of the experimenter until the 32 trials were presented, or the experimental session had to be stopped because of the participant's behaviour.


#### Data analysis

```{r data set_oxf}
attrition_oxf <- dplyr::filter(attrition, location=="Oxford")
n_trials <- nrow(attrition_oxf)
n_sessions <- n_distinct(attrition_oxf$session_id)
n_participants <- n_distinct(attrition_oxf$child_id)
n_trials_valid <- nrow(dplyr::filter(
	attrition_oxf,
	is_valid_participant,
	is_valid_trial
))
n_sessions_valid <- attrition_oxf |>
	distinct(child_id, .keep_all = TRUE) |>
	pull(is_valid_participant) |>
	sum()

n_participants_valid <- n_distinct(
	attrition_oxf[attrition_oxf$is_valid_participant, ]$child_id
)

n_exc_prime <- sum(!attrition_oxf$is_valid_gaze_prime)
n_exc_test <- sum(!attrition_oxf$is_valid_gaze_test)
n_exc_test_each <- sum(!attrition_oxf$is_valid_gaze_test_each)
n_exc_participants <- sum(!attrition_oxf |>
						  	distinct(child_id, .keep_all = TRUE) |>
						  	pull(is_valid_participant), na.rm = TRUE)

n_exc_participants_vocab <- attrition_oxf |>
	distinct(child_id, .keep_all = TRUE) |>
	mutate(is_valid_vocab_size = !is_valid_vocab_size) |>
	pull(is_valid_vocab_size) |>
	sum(na.rm = TRUE)

n_longitudinal <- attrition_oxf |>
	dplyr::filter(
		is_valid_participant,
		is_valid_trial
	) |>
	distinct(child_id, session_n) |>
	count(child_id, name = "times") |>
	count(times)

n_trials_condition <- attrition_oxf |>
	dplyr::filter(is_valid_participant) |>
	count(trial_type, is_valid_trial) %>%
	split(janitor::make_clean_names(.$trial_type))
```

**Data processing**. We defined a time window of interest from 200 ms after target and distractor pictures onset until the end of the trial at 2,000 ms when both pictures disappeared from screen. The first 200 ms of the test phase were discarded to avoid modelling fixations driven by processes other than auditory word recognition [@fernald1998rapid; @fernald2001half]. Missing eye-tracker samples were interpolated using the last-observation-carried-forward [see @zettersten2022peekbank for a similar approach], with a maximum of 20 maximum consecutive missing samples being interpolated (an equivalent of `r round(20*1000/120, 2)`). Target looking probability was calculated as the empirical logit, using the number of samples inside the time bin in which the participant was looking at the target and distractor AOI (see @eq-elogit) [@barr2008analyzing; @agresti2012categorical], as follows:

$$
\eta' = \ln\bigg(\frac{\text{Target} + 0.5}{ \text{Distractor} + 0.5}\bigg)
$$ {#eq-elogit}

We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_sessions` testing sessions, generated from `r n_participants` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples (equivalent to 750 ms) during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or 50% valid samples (equivalent to 1,000 ms) during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). We also excluded trials in which participants did not provide at least 5% of valid samples (equivalent to 100 ms) of target or distractor looking in the test phase (*n* = `r format(n_exc_test_each, big.mark = ",")`) [see @floccia2020translation; @mani2012activation for a similar approach].

After trials that matched any of the aforementioned exclusion criteria from the data set, we excluded participants who did not provide at least two valid trials in each condition (*n* = `r n_exc_participants`), and participants with a vocabulary size lower than 42, which corresponds to 10% of the words in the OCDI vocabulary checklist (*n* = `r n_exc_participants_vocab`). The final data set included `r format(n_trials_valid, big.mark = ",")` trials from `r n_sessions_valid` testing sessions, generated by `r format(n_participants_valid, big.mark = ",")` distinct participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, `r n_longitudinal[2, 2]` provided data from two experimental sessions, and `r n_longitudinal[3, 2]` provided data from three experimental sessions. From the trials included in the final data set, `r n_trials_condition$unrelated_2$n` were *Unrelated* trials (`r n_trials_condition$unrelated$n` previously excluded), and `r n_trials_condition$non_cognate_2$n + n_trials_condition$cognate_2$n` were *Related*  trials(`r n_trials_condition$non_cognate$n + n_trials_condition$cognate$n` previously excluded).


```{r data-analysis}

r_info <- sessionInfo()

r_version <- glue::glue(r_info$R.version$major,
						r_info$R.version$minor,
						.sep = "."
)
stan_version <- "2.33.0"

rope_interval <- c(-0.1, +0.1)
```

**Modelling approach**. We used Bayesian Hierarchical General Additive Models (HGAMs) to model the data [@pedersen2019hierarchical], using a Gaussian distribution to model the the logit of target looking. First, we fit a model ($\mathcal{M}_0$) that included the main effects of *Condition* and *Age* as fixed effects in the model. We set an *a priori* contrast for the *Condition* predictor [@schad2020capitalize], comparing *Unrelated* and *Related* trials (sum-coded as `-0.5` and `+0.5`. Before entering the model, the *Age* predictor was standardised by subtracting from each observation the mean of the predictor, and dividing the result from the standard deviation of the predictor. We included the variable *Session*---which indexes individual testing sessions that may belong to the same participant---as grouping variable, nested within the *Participant* grouping variable---which indexes a distinct participant. This nested random effects structure incorporates the longitudinal design of data collection, in which multiple participants were tested more than once at different ages. We added by-session intercepts and *Condition* slopes, and by-participant intercepts and *Age* slopes. To model the time course of target looking across time bins, we included B-splines for the main effect of *Time*, and for the *Condition* predictor [@wood2017generalized]. For both splines, we specified $k = 8$ basis functions or *knots*. @eq-model shows a formal implementation of the model.

We implemented this model using `brms` [@burkner2017brms], an R interface to the Stan probabilistic language (`r stan_version`) [@carpenter2017stan]. We ran `r english::words(dim(model_fits_bcn$fit_0$fit)[2])` iteration chains using the by-default No U-Turn Sampler algorithm with `r format(brms::niterations(model_fits_bcn$fit_0), big.mark = ",")` iterations each and an additional `r format(brms::niterations(model_fits_bcn$fit_0), big.mark = ",")` warm-up iterations per chain.

\newpage

$$
\begin{aligned}
&\textbf{Target looking by participant } i \textbf{ in session } j \\
y_{ij} &\sim \mathcal{N}(\mu_{ij}, \sigma_{ij}) \\\\
&\textbf{Distributional parameters:} \\
\eta'(\mu_{ij}) &= (\beta_0 + u _{0_{ij}}) +
(\beta_1 + u _{1_{ij}}) \text{Condition} + \beta_{2} \text{Age} + \sum_{w = 1}^k b_{w} \beta_{3_{k}} \text{Time} + \\
\text{where:} \\
&\eta'\text{ is the empirical logit of target fixations} \\
&b_{w} \text{ is the cubic spline of the } w \text{ basis function} \\
&k \text{ is the number of knots in the spline }(k = 8) \\
&\textbf{Prior:} \\
\beta_{0-3} &\sim \mathcal{N}(0, 0.5) \\
u_{0-1_{ij}} &\sim \mathcal{N}(0, \sigma_{0-2})\\
b_{w} &\sim \text{MVN}(0, \tau) \\
\sigma_{0-1}, \tau &\sim \text{Exponential}(6)\\
\rho_{0-1} &\sim LKJCorr(6)\\
\text{where:}\\
&\rho_{0-1} \text{ are the correlation parameters for } \sigma_{0-2}
\end{aligned}
$$ {#eq-model}

### Results

#### Priming effects

We tested the differences between the conditions of interest in two ways. First, we examined the posterior distribution of the regression coefficients of the linear predictors in model $\mathcal{M}_0$ (see @eq-model). We assessed the practical relevance of the coefficients following @kruschke2018bayesian. We specified a region of practical equivalence (ROPE) from `r rope_interval[1]` to +`r rope_interval[2]`, in the logit scale. This region indicates the range of values that we considered equivalent to zero. We then summarised the posterior distribution of each regression coefficient with the 95% highest density interval (HDI). This interval contains the true value of this coefficient with 95% probability, given the data. Finally, we calculated the proportion of posterior samples in the 95% HDI that fell into the ROPE, noted as $p(\text{ROPE})$, which indicates the probability that the true value of the regression coefficient falls into the ROPE (and therefore should be considered equivalent to zero). For example, $p(\text{ROPE})=.80$ indicates that, given our data, there is a 80% probability that the true value of the coefficient falls within the ROPE, and can therefore be considered equivalent to zero.


```{r coefs-oxf}
get_posterior_summary <- function(model, data, vars_dict,
								  rope_interval = c(lower = -0.1, upper = +0.1),
								  ...) {
	out <- tidybayes::gather_draws(model, `b_.*`, regex = TRUE, ...) |>
		tidybayes::median_hdci() |>
		mutate(.variable_name = factor(.variable,
									   levels = names(vars_dict),
									   labels = vars_dict,
									   ordered = TRUE),
			   type = if_else(grepl("Intercept", .variable),
			   			   paste0("Intercepts (at ",
			   			   	   round(mean(data$age, 2)), " months)"),
			   			   "Slopes"),
			   parameter = if_else(grepl("Intercept", .variable),
			   					gsub("Intercept \\(|\\)", "", .variable),
			   					.variable),
			   .rope = get_rope_overlap(.lower, .upper, .rope = rope_interval)) |>
		arrange(type, .variable_name) |>
		select(.variable, .variable_name, .type = type, 
			   .value, .lower, .upper, .rope) |>
		ungroup()
	
	return(out)
}

get_rope_overlap <- function(.lower,
							 .upper,
							 .rope = c(-0.1, 0.1),
							 precision = 1e4) {
	int <- data.frame(.lower, .upper)
	fun <- \(x) approx(x, n = precision, method = "linear")
	int.seq <- purrr::map(apply(int, fun, MARGIN = 1), "y")
	overlap <- purrr::map_dbl(int.seq, \(x) mean((x >= .rope[1]) & x <= .rope[2]))
	return(overlap)
}

var_labels <- c("b_Intercept" = "Intercept",
				"b_age_std" = "Age (+1 SD)",
				"b_condition1" = "Condition (U vs. R/NC)",
				"b_condition2" = "Condition (R/NC vs. R/C)")

model_summary <- get_posterior_summary(model_fits_oxf$fit_oxf_0,
									   data_bcn,
									   vars_dict = var_labels,
									   rope_interval = rope_interval)


coefs <- model_summary |>
	mutate(.value = sprintf("%.3f", .value),
		   .ci = sprintf("[%.3f, %.3f]", .lower, .upper),
		   .rope = scales::percent(.rope, accuracy = 0.01)) |>
	split(janitor::make_clean_names(model_summary$.variable))
```

Overall, the average participant' target looking time exceeded chance levels, as indicated by the fact that the 95% HDI of the intercept term excluded zero ($\beta$ = `r coefs$b_intercept$.value`, 95% HDI = `r coefs$b_intercept$.ci`) and all of its posterior samples fell outside of the ROPE. The 95% HDI of the coefficient of *Age* had a positive sign, but did not exclude zero ($\beta$ = `r coefs$b_age_std$.value`, 95% HDI = `r coefs$b_age_std$.ci`), and overlapped completely with the ROPE, indicating that participants from all ages showed equivalent overall target word recognition. The 95% HDI of the contrast of the *Condition* predictor---comparing *Unrelated* and *Related* trials---included zero ($\beta$ = `r coefs$b_condition1$.value`, 95% HDI = `r coefs$b_condition1$.ci`), and `r coefs$b_condition1$.rope` of its posterior samples fell within the ROPE.

Second, we examined the differences between the priming conditions in the time course of the trial, incorporating the smooth functions of the HGAMs to generate marginal posterior predictions for each condition across for each time point. @fig-epreds-oxf shows the posterior predictions of the model for each condition, and a summary of the difference between the *Unrelated* and *Related* conditions, at each time point to test the practical relevance of these differences, were compared their 95% HDI against the [-0.1, +0.1] ROPE. This analysis revealed a similar pattern of results to the previously shown: predicted target looking for the three conditions overlaps across the full time course of the trial.

```{r fig-epreds-oxf}
#| label: fig-epreds-oxf
#| fig-cap: "Time course of target fixations in Study 1. A) Posterior mean predictions of the time course of target fixation in the test phase. B) Posterior mean prediction of the time course of the differences in target looking time between conditions. Intervals represent the 95% CrI of the posterior predictions. Lines indicate the mean of the posterior predictions."
#| fig-width: 6.5
#| fig-height: 6.5
make_std <- function(x, mean, sd) (x - mean) / sd

timebin_values <- make_std(
	seq(0, 16, length.out = 100),
	mean(data_bcn$timebin),
	sd(data_bcn$timebin))

nd <- expand_grid(distinct(data_oxf, condition),
				  timebin_std = timebin_values,
				  age_std = 0)

epreds <- tidybayes::add_epred_draws(nd, model_fits_oxf$fit_oxf_1,
									 re_formula = NA,
									 ndraws = NULL,
									 value = ".epred")

obs <- data_oxf |>
	summarise(.elog = mean(.elog),
			  .by = c(timebin_std, condition))

epreds_summary <- epreds |>
	ungroup() |>
	summarise(.value = tidybayes::mean_qi(.epred)[[1]],
			  .lower = tidybayes::mean_qi(.epred)[[2]],
			  .upper = tidybayes::mean_qi(.epred)[[3]],
			  .by = c(condition, timebin_std))

plot_epreds <- epreds |>
	ggplot(aes(timebin_std, .epred,
			   colour = condition,
			   fill = condition,
			   linetype = condition,
			   shape = condition)) +
	geom_hline(yintercept = 0,
			   colour = "grey") +
	stat_summary(fun.data = tidybayes::mean_qi,
				 geom = "ribbon",
				 alpha = 1 / 4,
				 linewidth = NA) +
	stat_summary(fun = "mean",
				 geom = "line",
				 linewidth = 3 / 4) +
	geom_point(
		data = obs,
		aes(y = .elog),
		stroke = 1,
		size = 2) +
	labs(x = "Time (ms)",
		 y = "Logit (Target looking)",
		 colour = "Condition",
		 fill = "Condition",
		 linetype = "Condition",
		 shape = "Condition") +
	scale_y_continuous(limits = c(-0.75, 1.25)) +
	scale_shape_manual(values = c(1, 2)) +
	scale_linetype_manual(values = rev(c("solid", "dashed", "dotdash"))) +
	theme(panel.grid.major.y = element_line(colour = "grey",
											linetype = "dotted"))

epreds_diff <- epreds |>
	pivot_wider(id_cols = c(timebin_std, .draw),
				names_from = "condition",
				values_from = ".epred",
				names_repair = janitor::make_clean_names) |>
	mutate(.epred = related - unrelated)

diffs_summary <- epreds_diff |>
	ungroup() |>
	summarise(.value = tidybayes::mean_qi(.epred)[[1]],
			  .lower = tidybayes::mean_qi(.epred)[[2]],
			  .upper = tidybayes::mean_qi(.epred)[[3]],
			  .by = c(timebin_std))

diffs_obs <- obs |> 
	pivot_wider(id_cols = c(timebin_std),
				names_from = "condition",
				values_from = ".elog",
				names_repair = janitor::make_clean_names) |>
	mutate(.epred = related - unrelated)


plot_diffs <- epreds_diff |>
	ggplot(aes(timebin_std, .epred)) +
	annotate(geom = "rect",
			 alpha = 1 / 4,
			 fill = "red",
			 linewidth = 0,
			 ymin = rope_interval[1],
			 ymax = rope_interval[2],
			 xmin = -Inf,
			 xmax = Inf) +
	geom_ribbon(data = diffs_summary,
				aes(ymin = .lower,
					ymax = .upper,
					y = .value),
				fill = "grey",
				linewidth = NA,
				alpha = 3 / 4) +
	geom_line(data = diffs_summary,
			  aes(y = .value),
			  colour = "black",
			  linewidth = 3 / 4) +
	geom_point(data = diffs_obs,
			   shape = 1,
			   stroke = 1,
			   size = 2) +
	# geom_hline(yintercept = rope_interval[1],
	# 		   colour = "red",
	# 		   linetype = "dotted") +
	# geom_hline(yintercept = rope_interval[2],
	# 		   colour = "red",
	# 		   linetype = "dotted") +
	labs(x = "Time (ms)",
		 y = "Logit P(Target looking)",
		 colour = "Comparison",
		 fill = "Comparison",
		 linetype = "Comparison") +
	# scale_y_continuous(limits = c(-0.25, 0.5)) +
	theme(panel.grid.major.y = element_blank())

plot_epreds + plot_diffs +
	plot_layout(ncol = 1, heights = c(0.6, 0.4)) &
	plot_annotation(tag_levels = "A") &
	# scale_y_continuous(limits = c(0.25, 0.75)) +
	scale_x_continuous(
		breaks = make_std(seq(0, 17, 3),
						  mean(data_bcn$timebin),
						  sd(data_bcn$timebin)),
		labels = \(x) format(seq(3e2, 2e3, 3e2),
							 big.mark = ",")) &
	theme(legend.position = "top",
		  legend.title = element_blank())
```

#### Age and vocabulary size effects

To test our hypotheses regarding the role of age and vocabulary size on the emergence of priming effects, we compared the fit of model $\mathcal{M}_0$ against the fit of other models including the two-way interaction between *Condition* and *Age* ($\mathcal{M}_1$), or the two-way interaction between *Condition* and *Vocabulary* ($\mathcal{M}_2$), and all main effects involved. As with *Age*, the *Vocabulary* predictor was standardised before entering the model. We compared the models using one-out cross-validation (LOO-CV) as a benchmark of model performance, using a Pareto-smoothed importance sampling (PSIS) approximation [@vehtari2017practical]. A better performance by models $\mathcal{M}_1$ or $\mathcal{M}_2$ over $\mathcal{M}_0$ would point to *Age* or *Vocabulary*, respectively, playing a substantial role in participants' word-recognition, or on the emergence of priming effects. @tbl-loos-oxf shows a summary of the predictive performance of the models, as quantified by the expected log-predictive density (*ELPD*), and its standard error (*SE*, a measure of uncertainty around the *ELPD*). Overall, all models, performed equivalently, as shown by the small difference in *ELPD*, relative to the uncertainty of the estimates. This suggests that participants' target looking during the test phase can be predicted with relative accuracy without taking into account the age or vocabulary size of the participants.

```{r tbl-loos-oxf}
#| label: tbl-loos-oxf
#| tbl-cap: "Leave-one-out cross validation outcomes, comparing the predictive performance of the models in Study 1. $\\Delta ELDP$: pairwise difference in $ELPD$ for two models. The difference is computed relative to the model with lowest $ELPD$ (best fitting model). $\\Delta ELDP_{SE}$: standard error of component-wise differences of *ELPD* between two models. $ELDP$: sum of expected log pointwise predictive density for a new data set. $ELDP_{SE}$: standard error of the $ELPD$, which indictes the uncertainty about the predictive performance for unknown future data." 
tbl_data <- brms::loo_compare(model_loos_oxf) |>
	as.data.frame() |>
	tibble::rownames_to_column("model") |>
	mutate(model = paste0(
		"Model ",
		as.numeric(gsub("fit_oxf_", "", model))),
		across(matches("diff"),
			   \(x) {
			   	x[1] <- NA
			   	return(x)
			   }),
		preds = case_when(
			model=="Model 0" ~ "$\\text{Age} + \\text{Condition}$",
			model=="Model 1" ~ "$\\text{Age} \\times \\text{Condition}$",
			model=="Model 2" ~ "$\\text{Vocabulary} \\times \\text{Condition}$"
		),
		model = case_when(
			model=="Model 0" ~ "$\\mathcal{M}_0$",
			model=="Model 1" ~ "$\\mathcal{M}_1$",
			model=="Model 2" ~ "$\\mathcal{M}_2$",
			.default = model),
	) |>
	select(model, preds, matches("elpd|diff")) |>
	relocate(matches("diff"), .after = matches("loo")) 

kable(tbl_data,
	  format.args = list(big.mark = ","), 
	  format = "latex",
	  digits = 2,
	  booktabs = TRUE,
	  escape = FALSE,
	  col.names = c(" ", "Predictors",
	  			  "$ELDP$", 
	  			  "$ELDP_{SE}$",
	  			  "$\\Delta ELDP$", 
	  			  "$\\Delta ELDP_{SE}$"),
	  align = "lrrrrr") 
```

### Discussion

We found strong evidence of successful word recognition across participants of all ages, but we did not observe any evidence of phonological priming. English monolingual participants from all ages showed an equivalent pattern of target looking in both *Related* and *Unrelated* trials. In conclusion, we failed to replicate the original studies by @mani2010infant and @mani2011phonological. The absence of a phonological priming effect suggest that either English monolinguals did not generate implicit labels for the prime pictures presented in silence, or that, if generated, such labels did not interact with the subsequent recognition of the target word. Both explanations conflict with both Mani and Plunkett's studies, and also with previous studies suggesting that infants 12-months and older already generate internal labels when presented with pictures of familiar objects [@duta2012erp; @styles2015infant].

Adding the predictors *Age* or *Vocabulary size* as predictors in the model, in interaction with *Condition* did not increase the fit of the model. This points to neither variable having a substantial influence in participants' target looking behaviour across conditions. These results diverge from previous studies reporting an increment in word recognition speed [@fernald1998rapid; @marchman2008speed], and stronger phonological priming effects in children with larger vocabulary sizes [@mani2011phonological; @chow2017spoken; @avila2021longitudinal]. Overall, this results suggest that our modification of the implicit naming task resulted in the loss of the originally reported effect.


## Study 2

The original planning of the present investigation was to run Study 1 first and once the procedure had been validated to start Study 2. However, right at the beginning of data collection, the outbreak of COVID-19 pandemic took place. At this point it was decided to run both experiments in parallel. Data collection at the Barcelona site proceeded at a faster rate than at Oxford. It was not until data collection was well advanced in Barcelona that the results of study 1 were available. This is the reason why Study 2 was run with the same procedure as Experiment 1.

### Methods

#### Participants

```{r}
#| label: participants-numbers
participants_bcn <- dplyr::filter(participants, location=="Barcelona")

n_participants_total <- nrow(distinct(participants_bcn, child_id))
n_sessions_total <- count(participants_bcn)

n_participants_lp <- participants_bcn |>
	distinct(lp, child_id) |>
	count(lp)

n_participants_lp_sex <- participants_bcn |>
	distinct(lp, sex, child_id) |>
	count(lp, sex)

n_participants_sessions <- participants_bcn |>
	count(child_id, name = "n_sessions") |>
	count(n_sessions) |>
	group_split(n_sessions) |>
	purrr::set_names(paste0("session_", 1:3)) |>
	purrr::map("n")

n_sessions_lp <- participants_bcn |>
	summarise(across(age, lst(mean, sd, min, max)), n = n(), .by = c(lp)) |>
	mutate(across(age_mean:age_max, \(x) round(x, 2))) |>
	group_split(lp) |>
	purrr::set_names(janitor::make_clean_names(unique(participants_bcn$lp)))

n_sessions_dominance_lp <- count(participants_bcn, lp, test_language) |>
	group_split(test_language) |>
	purrr::set_names(c("catalan", "spanish")) |>
	purrr::map(group_split, lp)

n_sessions_lp <- participants_bcn |>
	count(lp) |>
	group_split(lp) |>
	purrr::set_names(c("monolingual", "bilingual")) |>
	purrr::map("n")

suppressWarnings({
	time_diffs <- participants_bcn |>
		arrange(child_id, session_id, age) |>
		mutate(n_session = 1:n()) |>
		select(child_id, session_id, session_n, age) |>
		dplyr::filter(child_id %in% participants_bcn$child_id[duplicated(participants_bcn$child_id)]) |>
		pivot_wider(
			id_cols = child_id,
			names_from = session_n,
			values_from = age,
			names_repair = janitor::make_clean_names
		) |>
		rowwise() |>
		mutate(
			diff_1 = x2 - x1, diff_2 = x3 - x2,
			diff_min = min(diff_1, diff_2, na.rm = TRUE),
			diff_max = max(diff_1, diff_2, na.rm = TRUE)
		) |>
		ungroup() |>
		summarise(
			diff_min = min(diff_min, na.rm = TRUE),
			diff_max = max(diff_max, na.rm = TRUE)
		)
})
```

We collected data from `r n_participants_total` children living in the Metropolitan Area of Barcelona (Spain), tested at the Laboratori de Recerca en Infància at the Universitat Pompeu Fabra. Families were recruited from maternity rooms in private hospitals and social media, and contacted via phone when the child's age spanned between 20 and 32 months. From the `r n_participants_total` children that participated, `r n_participants_sessions$session_1` participated once, `r n_participants_sessions$session_2` participated twice, and `r n_participants_sessions$session_3` participated three times. Recurrent participants were tested with at least `r round(time_diffs$diff_min[1], 2)` months of difference. We gathered a total of `r n_sessions_total$n` testing sessions. Participants were divided into monolinguals and bilinguals based on their relative degree of exposure to Catalan and Spanish, estimated using an adaptation of the Language Exposure Questionnaire [LEQ, @bosch2001evidence]. We categorised participants as monolingual if exposed to more than 80% or more of the time to their dominant language, and as bilingual otherwise. `r english::Words(n_participants_lp$n[1])` of the participants were categorised as monolinguals (`r n_participants_lp_sex$n[1]` female, `r n_participants_lp_sex$n[2]` male) and `r n_participants_lp$n[2]` as Catalan/Spanish bilinguals (`r n_participants_lp_sex$n[3]` female, `r n_participants_lp_sex$n[4]` male) (see @tbl-participants for a detailed summary of participants' age and language profile). Participants' vision was normal, none used glasses or any other type of vision corrector.

```{r vocab-values}
vocabulary_bcn <- vocabulary |>
	inner_join(select(participants_bcn, session_id, lp, age_group),
			   by = join_by(session_id)
	)

vocab_means <- vocabulary_bcn |>
	summarise(across(c(total_prop, l1_prop), lst(mean, sd)),
			  n = n(),
			  .by = c(age_group, lp)
	) %>%
	mutate(across(matches("prop"), scales::percent)) %>%
	split(paste0("age_", gsub(" months", "", .$age_group))) |>
	purrr::map(\(x) split(x, tolower(x$lp)))

n_imputed <- table(vocabulary_bcn$is_imputed)[2]
prop_imputed <- scales::percent(n_imputed / nrow(vocabulary_bcn))
n_pool <- nrow(bvq_data$vocabulary)


n_items <- bvq_data$pool |>
	unnest_longer(version) |>
	count(language, version) |>
	summarise(
		min = min(n),
		max = max(n),
		.by = language
	)

n_categories <- n_distinct(bvq_data$pool$semantic_category)
```

We collected vocabulary data using parental responses to the Barcelona Vocabulary Questionnaire [BVQ, @garcia-castro2023bvq], an online vocabulary checklist developed to assess the vocabulary size of Catalan-Spanish bilingual toddlers, and inspired in several adaptations of the the Communicative Developmental Inventory [CDI, @fenson1994variability]. This questionnaire has four versions, each including a different but overlapping subset of words, from a total pool of `r n_pool` words from `r n_categories` functional-semantic categories. Each version included a Catalan and a Spanish vocabulary checklist. Catalan checklists contained between `r n_items$min[1]` and `r n_items$min[2]` words, and Spanish checklists contained between `r n_items$min[2]` and `r n_items$min[2]` words (see the Methods section of Chapter 1 for a detailed description of the questionnaire. Participants were randomly allocated to one of the four versions. Recurrent participants were always allocated to the same version. Families received a link to the BVQ immediately after each experimental session, and were given two weeks to fill it.

Following the same procedure as in Study 1, we calculated participants' vocabulary size as the number of words that caregivers reported their child to *understand* or *understand and say* in the dominant language of the child (i.e., the language of test). `r english::Words(n_imputed)` (`r prop_imputed`) families failed to provide a complete response to the vocabulary checklist within the two-week time limit. We imputed missing vocabulary size scores using single imputation, taking the vocabulary size scores of a pool of `r n_pool` additional participants for which a successful response for the questionnaire had been gathered. We used participants' age in months and their language profile (monolingual or bilingual) as predictors. We used the `mice` R package [@van2011mice] to perform imputation using the Bayesian linear regression method (see Appendix B).

```{r fig-vocabulary}
#| label: fig-vocabulary-bcn
#| fig-cap: "Participant receptive vocabulary sizes across ages and language profiles in Study 2. For descritive purposes, mean and standard error of the mean are indicated, as calculated using a linear regression model."
#| fig-width: 6
#| fig-height: 3
vocab_plot_data |>
	mutate(lp = factor(lp, levels = c("Monolingual", "Bilingual"))) |>
	dplyr::filter(study == "Study 2 (Catalan/Spanish)") |>
	ggplot(aes(age, l1_count)) +
	facet_wrap(~lp) +
	geom_point(size = 2,
			   shape = 1,
			   colour = "grey",
			   alpha = 3 / 4,
			   stroke = 1) +
	geom_smooth(method = "lm",
				formula = "y ~ x",
				colour = "black",
				fill = "black") +
	labs(x = "Age (months)",
		 y = "Vocabulary size",
		 colour = "Group",
		 fill = "Group") +
	scale_x_continuous(breaks = seq(0, 40, 2)) +
	scale_y_continuous(limits = c(0, 575),
					   breaks = seq(0, 1e3, 100)) +
	theme(panel.grid.major.y = element_line(
		linetype = "dotted",
		colour = "grey"),
		legend.position = "none",
		axis.title.x = element_blank(),
		legend.title = element_blank())
```

#### Design

Participants were presented with 32 trials in random order, which belonged to three conditions: *Unrelated* trials (*n* = 16), *Related/Non-cognate* (*n* = 8), and *Related/Cognate* (*n* = 8). In *Unrelated* trials, the target label shared phonological onset with the Catalan and Spanish labels of the prime picture (e.g., prime: /\textipa{"gos}/$_{\text{CAT}}$--/\textipa{"pe.ro}/$_{\text{SPA}} [\text{dog}]$, target: /\textipa{"ka.za}/$_{\text{CAT}} [\text{house}]$, for a child tested in Catalan). In *Related/Non-cognate* trials, the target shared phonological onset with the prime label in the test language, but not with the prime label in the other language (e.g., prime: /**\textipa{m}**\textipa{i"}\textdyoghlig\textipa{o}/$_{\text{CAT}}$ (/\textipa{kal.Te"in}/ $_{\text{SPA}}) [\text{dog}]$, target: /**\textipa{m}**\textipa{u"nE.D@}/$_{\text{CAT}} [\text{coin}]$). In *Related/Cognate* trials, the target shared phonological overlap with both English and Spanish prime labels (e.g., prime: /**\textipa{"a}**\textipa{bR@}/$_{\text{CAT}}$--/**\textipa{"a}**\textipa{r.Bol}/ $_{\text{SPA}}) [\text{tree}]$, target: /**\textipa{@}**\textipa{"BE.j@}$/$_{\text{CAT}} [\text{bee}]$).

#### Stimuli

```{r stimuli-values}
n_words <- length(unique(with(stimuli, unlist(prime, target, distractor))))
```

We created six stimuli lists: three in Catalan, and three in Spanish. Lists were created following the same constraints as in Study 1,  but now considering the cross-linguistic phonological relationship between Catalan and Spanish. Extracting lexical frequencies from the Catalan and Spanish corpora in the CHILDES database was not possible, given the low number of participants and tokens included. We mapped the English lexical frequencies onto their Catalan and Spanish translation equivalents [see @fourtassi2020growth and @garcia2023cognate for similar approaches]. The auditory stimuli were natural exemplars of the selected target words, spoken by a proficient female bilingual speaker of Catalan (Central variety) and Castilian Spanish, who was instructed to pronounce each word in a toddler-directed manner. Catalan audios had an average duration of `r durations$catalan$duration_mean` ms (*SD* = `r durations$catalan$duration_sd`, *Range* = `r durations$catalan$duration_min`--`r durations$catalan$duration_max`), and Spanish audios had an average duration of  `r durations$spanish$duration_mean` ms (*SD* = `r durations$spanish$duration_sd`, *Range* = `r durations$spanish$duration_min`--`r durations$spanish$duration_max`). New visual stimuli were created to accommodate the words included in the new stimuli lists, and possible cultural differences in the typicality of the exemplars shown in the pictures (see Appendix A for a detailed description of the stimuli).


#### Procedure

Same as in Study 1. We run the study on Windows 10 64-bit, using custom Matlab (2018a 64-bit) script using the PsychToolbox-3 extension (3.0.15 64-bit) to present the stimuli on a 23-inches screen with $1929\times1080$ resolution, and the Tobii Analytics SDK 3.0 to interact with the eye-tracker (Tobii TX300 and Tobii Pro Sprectrum, Tobii Technology, Stockholm, Sweden) while the experiment was running.

#### Data analysis

```{r data set}
attrition_bcn <- dplyr::filter(attrition, location == "Barcelona")
n_trials <- nrow(attrition_bcn)
n_sessions <- n_distinct(attrition_bcn$session_id)
n_participants <- n_distinct(attrition_bcn$child_id)
n_trials_valid <- nrow(dplyr::filter(
	attrition_bcn,
	is_valid_participant,
	is_valid_trial
))
n_sessions_valid <- sum(distinct(attrition_bcn,
								 session_id,
								 .keep_all = TRUE
)$is_valid_participant)
n_participants_valid <- n_distinct(
	attrition_bcn[attrition_bcn$is_valid_participant, ]$child_id
)

n_exc_prime <- sum(!attrition_bcn$is_valid_gaze_prime)
n_exc_test <- sum(!attrition_bcn$is_valid_gaze_test)
n_exc_test_each <- sum(!attrition_bcn$is_valid_gaze_test_each)
n_exc_participants <- sum(!distinct(attrition_bcn,
									session_id,
									.keep_all = TRUE
)$is_valid_participant)
n_exc_participants_vocab <- sum(!distinct(attrition_bcn,
										  session_id,
										  .keep_all = TRUE
)$is_valid_vocab_size)

n_longitudinal <- attrition_bcn |>
	dplyr::filter(
		is_valid_participant,
		is_valid_trial
	) |>
	distinct(child_id, session_n) |>
	count(child_id, name = "times") |>
	count(times)
```


**Data processing**. We gathered data from `r format(n_trials, big.mark = ",")` trials from `r n_sessions` testing sessions, generated from `r n_participants` distinct participants. We excluded trials in which participants failed to provide 50% valid eye-tracking samples (equivalent to 750 ms) during the prime phase (*n* = `r format(n_exc_prime, big.mark = ",")`) or 50% valid samples (equivalent to 1,000 ms) during the target-distractor phase (*n* = `r format(n_exc_test, big.mark = ",")`). We also excluded trials in which participants did not provide at least 10% of valid samples (equivalent to 100 ms) for both the target *and* the distractor (*n* = `r format(n_exc_test_each, big.mark = ",")`).

After excluding trials that matched any of the aforementioned criteria from the data set, we excluded participants who did not provide at least two valid trials in each experimental condition (*n* = `r n_exc_participants`), and participants with a dominant-language vocabulary size lower than 10% (which depending on the version of the vocabulary questionnaire they were allocated to, varied from `r floor(min(n_items$min)*0.1)` and `r floor(max(n_items$max)*0.1)`)  (*n* = `r n_exc_participants_vocab`). The final data set included `r format(n_trials_valid, big.mark = ",")` trials from `r n_sessions_valid` testing sessions, generated by `r format(n_participants_valid, big.mark = ",")` distinct participants. Of those participants, `r n_longitudinal[1, 2]` provided data from one experimental session, and `r n_longitudinal[2, 2]` provided data from two experimental sessions. @tbl-attrition shows a detailed description of the trial attrition.

**Modelling approach**. We modelled the data following a similar approach as in Study 1, with the main difference that participants' language profile (*Group*) was now included as a predictor in the model, in interaction with the *Condition* predictor. We set two *a priori* contrasts for the *Condition* predictor: one comparing *Unrelated* and *Related/Non-cognate* trials (sum-coded as `-0.5` and `+0.5`, with *Related/Cognate* trials coded as `0`), and another comparing *Related/Non-cognate* and *Related/Cognate* trials (sum-coded as `-0.5` and `+0.5`, with *Unrelated* trials coded as `0`). In Study 2, the base model $\mathcal{M}_0$ included the the main effects of *Age*, *Condition*, and *Group*, and the two-way interaction between the *Condition* and  *Group* predictors. Contrast coding of the *Condition* predictor was the same as in Study 1. We set one *a priori* contrasts for the *Group* predictor, comparing *Monolingual* with *Bilingual* participants (sum-coded as `-0.5` and `+0.5`, respectively). To model the time course of target looking, we included B-splines for the main effect of *Time*, and for the two-way interaction between *Condition* and *Group*.

**Statistical inference**. Same procedure as in Study 1.

### Results

#### Priming effects

```{r coefs}
var_labels <- c("b_Intercept" = "Intercept",
				"b_age_std" = "Age (+1 SD)",
				"b_lp1" = "Group",
				"b_condition1" = "Condition (U vs. RN)",
				"b_condition2" = "Condition (RN vs. RC)",
				"b_condition1:lp1" = "Group \U00D7 Condition (U vs. RN)",
				"b_condition2:lp1" = "Group \U00D7 Condition (RN vs. RC)")

model_summary <- get_posterior_summary(model_fits_bcn$fit_0,
									   data_bcn,
									   vars_dict = var_labels,
									   rope_interval = rope_interval)

coefs <- model_summary |>
	mutate(.value = sprintf("%.3f", .value),
		   .ci = sprintf("[%.3f, %.3f]", .lower, .upper),
		   .rope = scales::percent(.rope, accuracy = 0.01)) |>
	split(janitor::make_clean_names(model_summary$.variable))
```

Overall, the average participants' looking time exceeded chance levels, as indicated by the fact that the 95% HDI of the intercept term excluded zero ($\beta$ = `r coefs$b_intercept$.value`, 95% HDI = `r coefs$b_intercept$.ci`), and that all of its posterior samples fell outside of the ROPE. The coefficient of *Age* had a positive sign, but its 95% HDI overlapped completely with the ROPE ($\beta$ = `r coefs$b_age_std$.value`, 95% HDI = `r coefs$b_age_std$.ci`), indicating that participants from all ages showed equivalent overall target word recognition. The 95% HDI of the coefficient of *Group* also included zero ($\beta$ = `r coefs$b_lp1$.value`, 95% HDI = `r coefs$b_lp1$.ci`) and completely overlapped with the ROPE, indicating an equivalent overall target preference in monolinguals and bilinguals,

The 95% HDI of the first contrast of the *Condition* predictor---comparing *Unrelated* and *Related/Non-cognate* trials---included zero ($\beta$ = `r coefs$b_condition1$.value`, 95% HDI = `r coefs$b_condition1$.ci`), and `r coefs$b_condition1$.rope` of its posterior samples overlapped with the ROPE. The 95% HDI of the second contrast, comparing *Related/Non-cognate* and *Related/Cognate* trials, also included zero ($\beta$ = `r coefs$b_condition2$.value`, 95% HDI = `r coefs$b_condition2$.ci`), and `r coefs$b_condition2$.rope` of its posterior samples overlapped with the ROPE. The overall target preference was equivalent across both pairwise condition comparisons. The interaction term between the first *Condition* contrast contained zero ($\beta$ = `r coefs$b_condition1_lp1$.value`, 95% HDI = `r coefs$b_condition1_lp1$.ci`), with `r coefs$b_condition1_lp1$.rope` of its posterior samples overlapping with the ROPE. The interaction term between the second *Condition* contrast also contained zero ($\beta$ = `r coefs$b_condition2_lp1$.value`, 95% HDI = `r coefs$b_condition2_lp1$.ci`), and `r coefs$b_condition1$.rope` of its posterior samples fell within the ROPE. The outcomes of this model provide strong evidence against differences between monolinguals and monolinguals, and inconclusive evidence for differences in overall target looking time across conditions.

```{r timecourse}
make_std <- function(x, mean, sd) (x - mean) / sd

timebin_values <- make_std(
	seq(0, 16, length.out = 100),
	mean(data_bcn$timebin),
	sd(data_bcn$timebin))

age_values <- make_std(
	c(20, 32),
	mean(data_bcn$age),
	sd(data_bcn$age))

nd <- expand_grid(distinct(data_bcn, condition, lp),
				  age_std = 0, timebin_std = timebin_values)

epreds <- tidybayes::add_epred_draws(nd,
									 model_fits_bcn$fit_0,
									 ndraws = NULL,
									 re_formula = NA) |> 
	mutate(lp = factor(lp, levels = c("Monolingual", "Bilingual")))

```

An analysis of the time course of target looking revealed a similar pattern of results (see @fig-epreds). Posterior mean prediction for the three conditions overlap across the full time course of the trial in both language groups.


```{r fig-epreds}
#| label: fig-epreds
#| fig-cap: "Time course of target fixations in Study 2. A) Posterior mean predictions of the time course of target fixation in the test phase. B) Posterior mean prediction of the time course of the differences in target looking time between conditions. Intervals represent the 95% CrI of the posterior predictions. Lines indicate the mean of the posterior predictions."
#| fig-width: 8
#| fig-height: 8
epreds_summary <- epreds |>
	ungroup() |>
	summarise(.value = tidybayes::mean_qi(.epred)[[1]],
			  .lower = tidybayes::mean_qi(.epred)[[2]],
			  .upper = tidybayes::mean_qi(.epred)[[3]],
			  .by = c(lp, condition, timebin_std)) 

obs <- data_bcn |>
	summarise(.elog = mean(.elog),
			  .by = c(timebin_std, lp, condition)) |> 
		mutate(lp = factor(lp, levels = c("Monolingual", "Bilingual")))

plot_epreds <- epreds |>
	ggplot(aes(timebin_std, .epred,
			   colour = condition,
			   fill = condition,
			   linetype = condition,
			   shape = condition)) +
	facet_wrap(~lp) +
	stat_summary(fun.data = tidybayes::mean_qi,
				 geom = "ribbon",
				 alpha = 1 / 4,
				 linewidth = NA) +
	stat_summary(fun = "mean",
				 geom = "line",
				 linewidth = 3 / 4) +
	geom_hline(yintercept = 0,
			   colour = "grey") +
	geom_point(data = obs,
			   aes(y = .elog),
			   size = 2,
			   stroke = 1) +
	labs(x = "Time (ms)",
		 y = "Logit (Target looking)",
		 colour = "Condition",
		 fill = "Condition",
		 linetype = "Condition",
		 shape = "Condition") +
	scale_linetype_manual(values = rev(c("solid", "dashed", "dotdash"))) +
	scale_y_continuous(limits = c(-0.75, 1.25)) +
	theme(panel.grid.major.y = element_line(
		colour = "grey",
		linetype = "dotted"))

epreds_diff <- epreds |>
	pivot_wider(id_cols = c(lp, timebin_std, .draw),
				names_from = "condition",
				values_from = ".epred",
				names_repair = janitor::make_clean_names) |>
	mutate(diff_1 = related_non_cognate - unrelated,
		   diff_2 = related_cognate - related_non_cognate) |>
	pivot_longer(matches("diff"),
				 names_to = "diff",
				 values_to = ".epred",
				 names_prefix = "diff_") |>
	mutate(diff = factor(diff,
						 levels = c(1, 2),
						 labels = c("Related/Non-cognate - Unrelated",
						 		   "Related/Cognate - Related/Non-cognate")))

diffs_summary <- epreds_diff |>
	ungroup() |>
	summarise(.value = tidybayes::mean_qi(.epred)[[1]],
			  .lower = tidybayes::mean_qi(.epred)[[2]],
			  .upper = tidybayes::mean_qi(.epred)[[3]],
			  .by = c(diff, lp, timebin_std))

diffs_obs <- obs |> 
	pivot_wider(id_cols = c(lp, timebin_std),
				names_from = "condition",
				values_from = ".elog",
				names_repair = janitor::make_clean_names) |>
	mutate(diff_1 = related_non_cognate - unrelated,
		   diff_2 = related_cognate - related_non_cognate) |>
	pivot_longer(matches("diff"),
				 names_to = "diff",
				 values_to = ".epred",
				 names_prefix = "diff_") |>
	mutate(diff = factor(diff,
						 levels = c(1, 2),
						 labels = c("Related/Non-cognate - Unrelated",
						 		   "Related/Cognate - Related/Non-cognate")))

plot_diffs <- epreds_diff |>
	ggplot(aes(timebin_std, .epred)) +
	facet_wrap(diff ~ lp,
			   labeller = labeller(
			   	diff = label_value,
			   	lp = \(x) return(""),
			   	.multi_line = FALSE)) +
	annotate(geom = "rect",
			 xmin = -Inf,
			 xmax = Inf,
			 ymin = rope_interval[1],
			 ymax = rope_interval[2],
			 fill = "red",
			 linewidth = 0,
			 alpha = 1 / 3,
			 linetype = "dotted") +
	geom_ribbon(data = diffs_summary,
				aes(ymin = .lower,
					ymax = .upper,
					y = .value),
				fill = "grey",
				linewidth = NA,
				alpha = 3 / 4) +
	geom_line(data = diffs_summary,
			  aes(y = .value),
			  colour = "black",
			  linewidth = 3 / 4) +
	geom_point(data = diffs_obs,
			   shape = 1,
			   stroke = 1,
			   size = 2) +
	labs(x = "Time (ms)",
		 y = "Logit p(Target looking)",
		 colour = "Comparison",
		 fill = "Comparison",
		 linetype = "Comparison") 
# scale_y_continuous(limits = c(-0.5, 0.5))

plot_epreds + plot_diffs +
	plot_layout(ncol = 1) &
	plot_annotation(tag_levels = "A") &
	# scale_y_continuous(limits = c(0.25, 0.75)) +
	scale_x_continuous(breaks = make_std(seq(0, 17, 3),
										 mean(data_bcn$timebin),
										 sd(data_bcn$timebin)),
					   labels = \(x) format(seq(3e2, 2e3, 3e2),
					   					 big.mark = ",")) &
	theme(legend.position = "top",
		  legend.title = element_blank())
```

#### Age and vocabulary size effects

A comparison between models including *Age* ($\mathcal{M}_{1}$), *L1 vocabulary* ($\mathcal{M}_{2}$), and *Total vocabulary* ($\mathcal{M}_{3}$) against model $\mathcal{M}_{0}$, which only included *Age* as a main effect is shown in @tbl-loos-bcn. Overall, all models performed equivalently, with the model $\mathcal{M}_{2}$ showing slightly better performance. The equivalent performance of all models suggests that participants' target looking during the test phase can be predicted with relative accuracy without taking into account *L1 vocabulary*, or *Total vocabulary* sizes. We now report the median and 95% HDI of the coefficients of $\mathcal{M}_{2}$, the best-fitting model.

```{r tbl-loos-bcn}
#| label: tbl-loos-bcn
#| tbl-cap: "Leave-one-out cross validation outcomes, comparing the predictive performance of the models in Study 1. $\\Delta ELDP$: pairwise difference in $ELPD$ for two models. The difference is computed relative to the model with lowest $ELPD$ (best fitting model). $\\Delta ELDP_{SE}$: standard error of component-wise differences of *ELPD* between two models. $ELDP$: sum of expected log pointwise predictive density for a new data set. $ELDP_{SE}$: standard error of the $ELPD$, which indictes the uncertainty about the predictive performance for unknown future data." 
tbl_data <- brms::loo_compare(model_loos_oxf) |>
	as.data.frame() |>
	tibble::rownames_to_column("model") |>
	mutate(model = paste0(
		"Model ",
		as.numeric(gsub("fit_oxf_", "", model))),
		across(matches("diff"),
			   \(x) {
			   	x[1] <- NA
			   	return(x)
			   }),
		# across(where(is.numeric), \(x) format(x, big.mark = ",")),
		preds = case_when(
			model=="Model 0" ~ "$\\text{Age} + \\text{Condition}$",
			model=="Model 1" ~ "$\\text{Age} \\times \\text{Condition}$",
			model=="Model 2" ~ "$\\text{Vocabulary} \\times \\text{Condition}$"
		),
		model = case_when(
			model=="Model 0" ~ "$\\mathcal{M}_0$",
			model=="Model 1" ~ "$\\mathcal{M}_1$",
			model=="Model 2" ~ "$\\mathcal{M}_2$",
			.default = model),
	) |>
	select(model, preds, matches("elpd|diff")) |>
	relocate(matches("diff"), .after = matches("loo")) 

kable(tbl_data,
	  format.args = list(big.mark = ","), 
	  format = "latex",
	  digits = 2,
	  booktabs = TRUE,
	  escape = FALSE,
	  col.names = c(" ", "Predictors",
	  			  "$ELDP$", 
	  			  "$ELDP_{SE}$",
	  			  "$\\Delta ELDP$", 
	  			  "$\\Delta ELDP_{SE}$"),
	  align = "lrrrrr") 
```

### Discussion

Paralleling the results from Study 1 participant' looking behaviour suggested robust word recognition, regardless of experimental condition, participant language profile, age, or vocabulary size. Monolinguals and bilinguals showed equivalent target looking behaviour in *Unrelated*, *Related/Non-cognate*, and *Related/Cognate* trials, suggesting that no phonological priming took place, either within languages or across languages. These results contrast with those of previous studies using a similar paradigm, which reported within-language priming effects in same-aged monolinguals [@mani2011phonological; @avila2021longitudinal] and younger [@mani2010infant; @duta2012erp; @styles2015infant], and cross-language priming in adults [@von2014bilinguals]. 

We anticipated participants' sensitivity to phonological priming to increase with the size of their lexicon, in the light of previous studies in which the maturation of the lexicon was associated with larger phonological interference in word recognition [@mani2011phonological; @chow2017spoken]. In Study 2, incorporating participants' age as a predictor in the model in interaction with the two contrasts of the *Condition* predictor did not increase the predictive performance of the model. Neither did vocabulary size. This suggests that the lack of evidence of phonological priming in participants in this study, either within or across languages, did not depend of participants lexical development status.

```{r doe-exposure}
doe_mon_exp <- participants_bcn |>
	dplyr::filter(lp=="Monolingual") |>
	separate(doe, c("doe_spanish", "doe_catalan", "doe_english", "doe_other"), sep = ", ") |>
	mutate(across(matches("doe"), as.double),
		   doe2 = ifelse(test_language == "Catalan",
		   			  doe_spanish, doe_catalan),
		   is_positive = doe2 > 0) |>
	count(is_positive)
```


## General discussion

In this chapter, we investigated the developmental trajectories of cross-language co-activation in the initial lexicon. We tested a large cohort of monolingual and bilingual toddlers in an implicit naming paradigm, in which we designed three experimental conditions to manipulate the phonological overlap between the prime and target words within and across languages. In Unrelated trials, prime and target were phonologically unrelated in both languages. In Related/Non-cognate trials, prime and target labels shared phonological onset only in the dominant language of participants, in which they were tested. In Related/Cognate trials, the prime label was a cognate: prime and target labels shared phonological onset in both languages. In Study 1, we attempted to replicate the original findings by @mani2010infant and @mani2011phonological in a same-aged English monolingual cohort. We found no evidence of phonological priming. In Study 2, we tested a cohort of monolingual and bilingual infants learning Catalan, Spanish, or both, and found similar results, with no evidence of phonological priming effect in either monolinguals or bilinguals. We did not find any effect of participants' age or vocabulary size.

The lack of priming effects in Studies 1 and 2 contrasts with previous findings of within- and cross-language priming using an implicit naming paradigm. In their seminal study, @mani2010infant and @mani2011phonological reported within-language priming effects in English monolingual infants. In bilinguals, evidence of cross-linguistic priming in a implicit naming paradigm was available in adults [@von2014bilinguals]. The priming effects shown in these studies reveal that infants and adults retrieve phonologically detailed word-forms when presented with pictures of familiar objects, which later interact with the subsequent auditory recognition of phonologically related words. Evidence of such implicit naming is available in infants as young as 14 months. Electrophysiological evidence reported by @duta2012erp and @styles2015infant suggests that, at this, age, infants lexicalise name-known pictures presented in silence, and that the generated phonological form is sensitive to subsequent mispronunciations of the word. The possibility that infants in the present investigation failed to retrieve phonological word forms is therefore unlikely.

We consider three scenarios under which implicit naming might have occurred in the experiments presented in this chapter, but our design failed to capture it. First, it is be possible that infants in both Studies 1 and 2 implicitly generated phonological labels for the primes, but such labels lacked the phonological detail to interact with the subsequent recognition of a phonologically related target word. This is unlikely, given that both monolinguals [@swingley2000spoken; @bailey2002phonological; @tamasi2017pupillometry] and bilinguals [@ramon2009vowel; @tamasi2016measuring] have been shown to encode lexical representations with high phonological detail from early ages.

A second possibility is that participants successfully retrieved a detailed phonological form of the prime labels, but such forms failed to interact with target recognition. This would be explained by the lack of strong associations between phonologically related lexical representations at these ages. But even if one considers the possibility that participants in Study 1 failed to show priming effects for this reason (for instance, the emergence of phonological associations might follow different trajectories in Catalan-Spanish infants, compared to English infants), the fact that English monolingual infants in Study 2 failed to show such priming effects contradicts previous findings on the same population, reporting priming phonological priming effects in even younger infants [@mani2010infant; @mani2011phonological].

Third, and most likely, the modifications of the implicit naming task in the present investigation might have reduced the chances of detecting the anticipated effects. The most critical difference between the original design of the implicit naming task by Mani and Plunkett and that of the present study is the absence of a pre-naming phase during the test phase. Target auditory labels were presented immediately after the offset of the prime picture. It is possible that such time interval was too short for participants to retrieve the phonological label of the prime picture before the target was presented. Such failure to generate phonological word-forms for prime labels would have prevented participants in Studies 1 and 2 from being affected by phonological priming effects during target word recognition.

```{r fig-mp}
#| label: fig-mp
#| fig-cap: "Distribution of lexical frequencies and word familiarity at 18 months for the stimuli in Mani and Plunkett (2010, 2011), and in Study 1. A) Lexical frequencies (expressed as Zipf scores) for prime and target words. Lexical frequences are shown for related and unrelated primes separately. B) Word familiarity scores for prime and target words, calculated as the proportion of participants in the OCDI norms that were reported by their caregivers to understand the word. Word familiarity scores are shown for related and unrelated primes separately."
#| fig-width: 7
#| fig-height: 3
mp <- read_csv(here("data", "03-chapter-3", "data", "mp-stimuli.csv"),
			   show_col_types = FALSE)

mp_means <- mp |>
	dplyr::filter(role != "distractor") |>
	mutate(condition = if_else(role == "target",
							   "related/unrelated", 
							   condition)) |>
	summarise(aoa_sd = sd(aoa, na.rm = TRUE),
			  aoa = mean(aoa, na.rm = TRUE),
			  freq_sd = sd(freq),
			  freq = mean(freq),
			  .by = c(role, condition, study))

mp |>
	dplyr::filter(role != "distractor") |>
	mutate(condition = if_else(role == "target",
							   "related/unrelated", condition
	)) |>
	ggplot(aes(condition, freq, colour = study, fill = study)) +
	facet_wrap(~role, scales = "free_x") +
	ggdist::geom_dots(
		side = "both",
		layout = "swarm",
		fill = "white",
		stroke = 1,
		position = position_dodge(width = 1),
		alpha = 1 / 3
	) +
	stat_summary(
		geom = "errorbar",
		fun.data = mean_se,
		width = 0.1,
		linewidth = 1 / 2,
		position = position_dodge(width = 1)
	) +
	stat_summary(
		geom = "point",
		fun = mean,
		size = 1.5,
		position = position_dodge(width = 1)
	) +
	labs(
		x = "Role",
		y = "Lexical frequency (Zipf)",
		colour = "Study",
		fill = "Study"
	) +
	mp |>
	dplyr::filter(role != "distractor") |>
	mutate(condition = if_else(role == "target",
							   "related/unrelated", condition
	)) |>
	ggplot(aes(condition, aoa, colour = study, fill = study)) +
	facet_wrap(~role, scales = "free_x") +
	ggdist::geom_dots(
		side = "both",
		layout = "swarm",
		fill = "white",
		stroke = 1,
		position = position_dodge(width = 1),
		alpha = 1 / 5
	) +
	stat_summary(
		geom = "errorbar",
		fun.data = mean_se,
		width = 0.1,
		linewidth = 1 / 2,
		position = position_dodge(width = 1)
	) +
	stat_summary(
		geom = "point",
		fun = mean,
		size = 1.5,
		position = position_dodge(width = 1)
	) +
	geom_text_repel(
		data = summarise(mp,
						 aoa = min(aoa, na.rm = TRUE),
						 word = word[which.min(aoa)],
						 .by = c(study, role, condition)
		),
		aes(label = word), max.overlaps = 100
	) |>
	labs(
		x = "Role",
		y = "Familiarity at 18 months",
		colour = "Study",
		fill = "Study"
	) +
	scale_y_continuous(
		labels = scales::percent,
		limits = c(0, 1)
	) +
	plot_layout(nrow = 1, guides = "collect") &
	plot_annotation(tag_levels = "A") &
	theme(
		legend.position = "top",
		legend.title = element_blank(),
		axis.title.x = element_blank(),
		panel.grid.major.y = element_line(
			colour = "grey",
			linetype = "dotted"
		)
	)
```

A difference in the difficulty of the stimuli might have influenced the results in the present study, compared to those of the original studies. When designing the stimuli lists, we considered three variables as indices of word difficult during recognition: lexical frequency, age of acquisition, and number of phonemes. The distribution of the three variables was equivalent across the three experimental conditions (see @tbl-stimuli), so it is unlikely that such differences cancelled out a possible priming effect. However, the stricter limitations under which we build the stimuli lists, might have lead to out stimuli lists including more difficult words than in the original study by @mani2010infant. We examined this possibility by comparing the distributions of the English words included in Study 1, with those included in @mani2010infant and @mani2011phonological (stimuli lists are identical in both studies). @fig-mp shows a comparison between the stimuli lists of the three studies in lexical frequency and word familiarity at 18 months. Overall, words included in Mani and Plunkett and in Study 1 have equivalent lexical frequency, and are know by a similar proportion of English monolinguals infants, according to the OCDI norms. This is the case for prime and target words across the related and the unrelated conditions. It is therefore unlikely that the lack of priming effects in Study 1 is due to an increased difficulty in the items included.

```{r discussion-oxf-vocab}
oxf_vocab <- vocabulary |>
	inner_join(dplyr::filter(
		attrition_participants,
		is_valid_participant),
		by = join_by(session_id)) |>
	inner_join(participants,
			   by = join_by(child_id, session_id, vocab_id)) |>
	dplyr::filter(test_language == "English") |>
	summarise(l1_count_sd = sd(l1_count),
			  l1_count = mean(l1_count),
			  .by = age_group) |>
	arrange(age_group)
```

Another possibility is that participants in the present study had smaller vocabulary sizes than those of participants in the original studies. This hypothesis is not easy to investigate, as quantitative vocabulary sizes were not reported in original studies. A more recent study by @avila2021longitudinal, in which phonological priming effects were found associated to participants vocabulary size, did provide summary statistics for participants vocabulary size scores. This study tested a cohort of monolingual German infants in a word recognition task, in which participants in which participants were presented with auditory primes and targets, which were phonologically related or unrelated.   The authors estimated participants' receptive vocabulary sizes using the *Fragebogen zur frühkindlichen Sprachentwicklung* [@szagun2009fragebogen], an adaptation of the CDI to German. Their cohort of participants showed receptive vocabulary sizes larger than those of participants in the present study. Participants in @avila2021longitudinal knew an average of 405.24 (*SD* = 96.29) at 21 months and 501.97	(*SD* = 73.41) at 24 months, which contrast with receptive vocabulary sizes of participants in Study 1: `r round(oxf_vocab$l1_count[1], 2)` at 21 months (*SD* = `r round(oxf_vocab$l1_count_sd[1], 2)`), and `r round(oxf_vocab$l1_count[2], 2)` (*SD* = `r round(oxf_vocab$l1_count_sd[2], 2)`) at 25 months.

In summary, we aimed to test the language non-selective hypothesis of lexical access in bilingual toddlers using an adaptation of the implicit naming paradigm. This adaptation involved target auditory labels immediately after the offset of prime pictures, instead of presenting the target labels after a baseline period of 2,000 after the offset of the prime pictures. In Study 1, we tested English monolinguals (same population as in the original studies) to establish a baseline to later test bilingual participants. We attempted to replicate the previously reported within-language phonological priming effect. We did not find evidence of such effect, suggesting that our modification of the original task was unsuccessful. Because data collection was conducted simultaneously for Studies 1 and 2, data in Catalan-Spanish monolinguals and bilinguals was available despite the failed replication in Study 1. In Study 2, we also found null pattern of results, in which neither monolinguals nor bilinguals showed evidence of within- or cross-language priming effects. Overall, our results suggest that the change in the timing of the trial disrupted the dynamics of word recognition in such way that priming effects were no longer detectable in our adaptation of the paradigm.

## Appendix D: Imputing vocabulary sizes

{{< include ../_appendix/_chapter-3_vocabulary-validity.qmd >}}

{{< pagebreak >}}

## Appendix E: Concurrent validity of comprehension estimates

{{< include ../_appendix/_chapter-3_vocabulary-imputation.qmd >}}

{{< pagebreak >}}
